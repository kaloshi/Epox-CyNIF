{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Epoxy_CyNif-AF + Background-Anchor + GenFill(exp)\n",
    "# Neu: Settings-Zeile laden (Apply settings)\n",
    "# (enth\u00c3\u00a4lt: robuste ZIP-Speicherung + clean-fix f\u00c3\u00bcr local/ring/hybrid)\n",
    "# ============================================================\n",
    "\n",
    "import os, re, json, zipfile, traceback, hashlib, datetime, tempfile, warnings, sys\n",
    "from typing import Optional\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import disk\n",
    "from skimage import morphology as morph\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from xml.etree import ElementTree as ET\n",
    "try:\n",
    "    import tifffile as tiff\n",
    "except Exception:\n",
    "    tiff = None\n",
    "\n",
    "# ---------- OME-Metadaten Helfer ----------\n",
    "def parse_ome_channels(ome_xml: str):\n",
    "    if not ome_xml:\n",
    "        return [], {}\n",
    "    root = ET.fromstring(ome_xml)\n",
    "    pixels = root.find('.//ome:Pixels', OME_NS)\n",
    "    if pixels is None:\n",
    "        return [], {}\n",
    "    channels = []\n",
    "    for idx, ch in enumerate(pixels.findall('ome:Channel', OME_NS), start=1):\n",
    "        channels.append({'Name': ch.get('Name', f'Channel-{idx}')})\n",
    "    px_sizes = {\n",
    "        'PhysicalSizeX': pixels.get('PhysicalSizeX'),\n",
    "        'PhysicalSizeXUnit': pixels.get('PhysicalSizeXUnit'),\n",
    "        'PhysicalSizeY': pixels.get('PhysicalSizeY'),\n",
    "        'PhysicalSizeYUnit': pixels.get('PhysicalSizeYUnit'),\n",
    "        'PhysicalSizeZ': pixels.get('PhysicalSizeZ'),\n",
    "        'PhysicalSizeZUnit': pixels.get('PhysicalSizeZUnit'),\n",
    "    }\n",
    "    return channels, px_sizes\n",
    "\n",
    "\n",
    "def sanitize_pixel_sizes(px_sizes):\n",
    "    meta = {}\n",
    "    for key, value in (px_sizes or {}).items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        if key.endswith('Unit'):\n",
    "            meta[key] = value\n",
    "        else:\n",
    "            try:\n",
    "                meta[key] = float(value)\n",
    "            except (TypeError, ValueError):\n",
    "                pass\n",
    "    return meta\n",
    "\n",
    "\n",
    "\n",
    "ACE_PARAMS = dict(\n",
    "    radii=(5, 15, 45),\n",
    "    alpha=6.0,\n",
    "    iterations=1,\n",
    "    clip=(0.2, 99.8),\n",
    "    radius=None,\n",
    "    preserve_background=True,\n",
    "    max_gain=3.0,\n",
    "    engine='internal',\n",
    "    post_enabled=True\n",
    ")\n",
    "\n",
    "\n",
    "def ace_local_equalize(\n",
    "    image: np.ndarray,\n",
    "    *,\n",
    "    radii=(5, 15, 45),\n",
    "    alpha: float = 6.0,\n",
    "    iterations: int = 1,\n",
    "    clip=(0.2, 99.8),\n",
    "    radius=None,\n",
    "    preserve_background: bool = True,\n",
    "    max_gain: Optional[float] = 3.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"ACE-inspired local equalisation with safeguards for fluorescence data.\"\"\"\n",
    "    # NumPy-kompatibel: erst asarray, dann copy\n",
    "    work = np.asarray(image, dtype=np.float32)\n",
    "    if work is image or work.base is image:\n",
    "        work = work.copy()\n",
    "    if work.size == 0:\n",
    "        return work\n",
    "\n",
    "    clip = clip if clip not in (None, False) else None\n",
    "    base_lo, base_hi = (float(work.min()), float(work.max()))\n",
    "    if clip:\n",
    "        lo_ref, hi_ref = np.percentile(work, clip)\n",
    "    else:\n",
    "        lo_ref, hi_ref = base_lo, base_hi\n",
    "    if hi_ref <= lo_ref + 1e-6:\n",
    "        hi_ref = lo_ref + 1.0\n",
    "\n",
    "    if radius:\n",
    "        base_r = max(1, int(radius))\n",
    "        radii = sorted({max(1, base_r // 4), max(1, base_r // 2), base_r})\n",
    "    else:\n",
    "        radii = tuple(int(max(1, r)) for r in (radii or (5, 15, 45)))\n",
    "\n",
    "    alpha = float(max(1.0, alpha))\n",
    "    iterations = max(1, int(iterations))\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        accum = np.zeros_like(work, dtype=np.float32)\n",
    "        for radius in radii:\n",
    "            size = radius * 2 + 1\n",
    "            local_mean = ndi.uniform_filter(work, size=size, mode='reflect')\n",
    "            diff = work - local_mean\n",
    "            scale = alpha / (np.percentile(np.abs(diff), 98.0) + 1e-6)\n",
    "            response = np.clip(diff * scale, -1.0, 1.0)\n",
    "            accum += response\n",
    "        work = work + accum / float(len(radii))\n",
    "\n",
    "    if clip:\n",
    "        lo_curr, hi_curr = np.percentile(work, clip)\n",
    "        rng_curr = float(max(hi_curr - lo_curr, 1e-6))\n",
    "        rng_ref = float(max(hi_ref - lo_ref, 1e-6))\n",
    "        work = (work - lo_curr) * (rng_ref / rng_curr) + lo_ref\n",
    "\n",
    "    if preserve_background:\n",
    "        zero_mask = image <= 0\n",
    "        work[zero_mask] = 0.0\n",
    "\n",
    "    if max_gain and max_gain > 1.0:\n",
    "        mask = image > 0\n",
    "        if np.any(mask):\n",
    "            base = np.maximum(image[mask], 1e-6)\n",
    "            ratio = work[mask] / base\n",
    "            np.clip(ratio, 1.0 / max_gain, max_gain, out=ratio)\n",
    "            work[mask] = ratio * base\n",
    "\n",
    "    np.clip(work, 0.0, None, out=work)\n",
    "    return work\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5.2b UniFORM HISTOGRAM-BASED NORMALIZATION (Dynamic background aware)\n",
    "# =============================================================================\n",
    "\n",
    "def _histnorm_sample_values(image, step=4, max_samples=5_000_000):\n",
    "    \"\"\"Downsample an image to a manageable sample of pixel intensities.\"\"\"\n",
    "    arr = image[::step, ::step].astype(np.float64, copy=False)\n",
    "    flat = arr.ravel()\n",
    "    if flat.size > max_samples:\n",
    "        stride = int(max(1, flat.size // max_samples))\n",
    "        flat = flat[::stride]\n",
    "    return flat\n",
    "\n",
    "\n",
    "def _histnorm_trimmed_median(values, drop_upper=0.3):\n",
    "    arr = np.asarray(values, dtype=np.float64)\n",
    "    if arr.size == 0:\n",
    "        return 0.0\n",
    "    arr.sort()\n",
    "    keep = int(np.ceil(arr.size * (1.0 - float(drop_upper))))\n",
    "    keep = int(np.clip(keep, 1, arr.size))\n",
    "    return float(np.median(arr[:keep]))\n",
    "\n",
    "\n",
    "def _histnorm_background_peak(values, bins=512, focus_fraction=0.45):\n",
    "    if values.size == 0:\n",
    "        return 0.0\n",
    "    vmax = float(values.max()) if values.size else 0.0\n",
    "    if vmax <= 0:\n",
    "        return 0.0\n",
    "    hist, edges = np.histogram(values, bins=bins, range=(0.0, vmax))\n",
    "    if hist.sum() == 0:\n",
    "        return 0.0\n",
    "    smooth = ndi.gaussian_filter1d(hist.astype(np.float64), sigma=1.25, mode='nearest')\n",
    "    limit = max(4, int(len(smooth) * float(focus_fraction)))\n",
    "    idx = int(np.argmax(smooth[:limit]))\n",
    "    return float((edges[idx] + edges[idx + 1]) * 0.5)\n",
    "\n",
    "\n",
    "def _histnorm_is_reference_channel(name):\n",
    "    lname = (name or '').lower()\n",
    "    if not lname:\n",
    "        return True\n",
    "    blocked = (\n",
    "        'autoflu', 'blank', ' none', 'none(', 'none_', 'background', 'unmix',\n",
    "        'donor', 'spill', 'saibr', 'artifact'\n",
    "    )\n",
    "    return not any(token in lname for token in blocked)\n",
    "\n",
    "\n",
    "def _histnorm_is_af_channel(name):\n",
    "    lname = (name or '').lower()\n",
    "    return 'autoflu' in lname or ' af ' in lname or lname.startswith('af ') or lname.endswith(' af') or '(af' in lname\n",
    "\n",
    "\n",
    "def _histnorm_cycle_groups(channel_count, cycle_json_path):\n",
    "    cycle_path = Path(cycle_json_path) if cycle_json_path else None\n",
    "    groups = {}\n",
    "    idx_to_cycle = {}\n",
    "    names_from_json = None\n",
    "    if cycle_path and cycle_path.exists():\n",
    "        with open(cycle_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        names_from_json = data.get('channel_names')\n",
    "        offsets = data.get('offsets') or {}\n",
    "        counts = data.get('counts_selected') or data.get('counts') or {}\n",
    "        for key, start in offsets.items():\n",
    "            try:\n",
    "                start_idx = int(start)\n",
    "            except (TypeError, ValueError):\n",
    "                continue\n",
    "            count_val = counts.get(str(key)) or counts.get(int(key)) or counts.get(key)\n",
    "            try:\n",
    "                count_val = int(count_val)\n",
    "            except (TypeError, ValueError):\n",
    "                count_val = 0\n",
    "            if count_val <= 0:\n",
    "                continue\n",
    "            end_idx = min(channel_count, start_idx + count_val)\n",
    "            idxs = list(range(start_idx, end_idx))\n",
    "            if not idxs:\n",
    "                continue\n",
    "            cycle_id = str(key)\n",
    "            groups[cycle_id] = idxs\n",
    "            for idx in idxs:\n",
    "                idx_to_cycle[idx] = cycle_id\n",
    "    if not groups:\n",
    "        groups['1'] = list(range(channel_count))\n",
    "        idx_to_cycle = {idx: '1' for idx in range(channel_count)}\n",
    "    return groups, idx_to_cycle, names_from_json\n",
    "\n",
    "\n",
    "def _histnorm_channel_statistics(stack, channel_names, sample_step, low_focus_percentile, high_clip_percentile):\n",
    "    stats = []\n",
    "    C = stack.shape[0]\n",
    "    for idx in range(C):\n",
    "        image = stack[idx]\n",
    "        sample = _histnorm_sample_values(image, step=sample_step)\n",
    "        if sample.size == 0:\n",
    "            sample = image.astype(np.float64, copy=False).ravel()\n",
    "        max_val = float(sample.max()) if sample.size else 0.0\n",
    "        high_clip = np.percentile(sample, high_clip_percentile) if sample.size else 0.0\n",
    "        if not np.isfinite(high_clip) or high_clip <= 0:\n",
    "            high_clip = max_val\n",
    "        if high_clip <= 0:\n",
    "            high_clip = max_val if max_val > 0 else 1.0\n",
    "        clipped = sample[sample <= high_clip]\n",
    "        if clipped.size == 0:\n",
    "            clipped = sample\n",
    "        focus_cut = np.percentile(clipped, low_focus_percentile) if clipped.size else 0.0\n",
    "        focus_vals = clipped[clipped <= focus_cut] if clipped.size else clipped\n",
    "        if focus_vals.size < 128:\n",
    "            focus_vals = clipped\n",
    "        bg_peak = _histnorm_background_peak(focus_vals, bins=512)\n",
    "        pct = np.percentile(clipped, [0.1, 1.0, 5.0, 50.0, 95.0, 99.5]) if clipped.size else np.zeros(6)\n",
    "        stats.append({\n",
    "            'index': idx,\n",
    "            'name': channel_names[idx] if idx < len(channel_names) else f'Ch{idx:02d}',\n",
    "            'bg': float(bg_peak),\n",
    "            'p001': float(pct[0]),\n",
    "            'p1': float(pct[1]),\n",
    "            'p5': float(pct[2]),\n",
    "            'p50': float(pct[3]),\n",
    "            'p95': float(pct[4]),\n",
    "            'p995': float(pct[5]),\n",
    "        })\n",
    "    return stats\n",
    "\n",
    "\n",
    "def run_uniform_histogram_normalization_dynamic(\n",
    "    input_path=None,\n",
    "    output_path=None,\n",
    "    channel_names=None,\n",
    "    cycle_json_path='split_cycles_out_fixed/channel_map_applied.json',\n",
    "    sample_step=4,\n",
    "    low_focus_percentile=35.0,\n",
    "    high_clip_percentile=99.8,\n",
    "    drop_upper_fraction=0.35,\n",
    "    align_spread=True,\n",
    "    min_scale=0.9,\n",
    "    max_scale=1.1,\n",
    "    af_extra_pull=0.2,\n",
    "    max_shift=4000,\n",
    "    output_suffix='_Histo_Norm',\n",
    "    log_preview=5\n",
    "):\n",
    "    \"\"\"Dynamic UniFORM-style histogram normalization with per-cycle references.\"\"\"\n",
    "    if input_path is None:\n",
    "        input_path = IMG_PATH\n",
    "    input_path = Path(input_path)\n",
    "    if output_path is not None:\n",
    "        output_path = Path(output_path)\n",
    "    if tiff is None:\n",
    "        raise RuntimeError(\"tifffile not available \u00e2\u20ac\u201c required for OME-TIFF normalization\")\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"[5.2b] UniFORM HISTOGRAM-BASED NORMALIZATION (dynamic)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"[INFO] Input: {input_path}\")\n",
    "\n",
    "    with tiff.TiffFile(str(input_path)) as tf:\n",
    "        fused_stack = tf.asarray()\n",
    "        ome_xml = getattr(tf, 'ome_metadata', None)\n",
    "\n",
    "    if fused_stack.ndim == 2:\n",
    "        fused_stack = fused_stack[None, ...]\n",
    "    elif fused_stack.ndim > 3:\n",
    "        fused_stack = np.squeeze(fused_stack)\n",
    "    fused_stack = fused_stack.astype(np.uint16, copy=False)\n",
    "\n",
    "    ome_channel_names = []\n",
    "    px_meta = {}\n",
    "    if 'parse_ome_channels' in globals():\n",
    "        try:\n",
    "            channels, px_sizes = parse_ome_channels(ome_xml) if ome_xml else ([], {})\n",
    "        except Exception as exc:\n",
    "            print(f\"[WARN] OME metadata parsing failed: {exc}\")\n",
    "            channels, px_sizes = [], {}\n",
    "        if channels:\n",
    "            ome_channel_names = [ch.get('Name', f'Channel_{idx+1:02d}') for idx, ch in enumerate(channels)]\n",
    "        if px_sizes:\n",
    "            px_meta = sanitize_pixel_sizes(px_sizes)\n",
    "\n",
    "    groups, idx_to_cycle, names_from_json = _histnorm_cycle_groups(fused_stack.shape[0], cycle_json_path)\n",
    "\n",
    "    if channel_names is not None:\n",
    "        resolved_names = list(channel_names)\n",
    "    elif ome_channel_names:\n",
    "        resolved_names = ome_channel_names\n",
    "    elif names_from_json:\n",
    "        resolved_names = names_from_json\n",
    "    else:\n",
    "        resolved_names = []\n",
    "\n",
    "    if len(resolved_names) < fused_stack.shape[0]:\n",
    "        resolved_names = list(resolved_names)\n",
    "        for idx in range(len(resolved_names), fused_stack.shape[0]):\n",
    "            resolved_names.append(f'Channel_{idx:02d}')\n",
    "\n",
    "    stats = _histnorm_channel_statistics(\n",
    "        fused_stack,\n",
    "        resolved_names,\n",
    "        sample_step=sample_step,\n",
    "        low_focus_percentile=low_focus_percentile,\n",
    "        high_clip_percentile=high_clip_percentile\n",
    "    )\n",
    "\n",
    "    for stat in stats:\n",
    "        stat['cycle'] = idx_to_cycle.get(stat['index'], 'NA')\n",
    "\n",
    "    backgrounds = np.array([stat['bg'] for stat in stats], dtype=np.float64)\n",
    "    ref_mask = np.array([_histnorm_is_reference_channel(stat['name']) for stat in stats], dtype=bool)\n",
    "\n",
    "    global_candidates = backgrounds[ref_mask] if ref_mask.any() else backgrounds\n",
    "    global_ref = _histnorm_trimmed_median(global_candidates, drop_upper=drop_upper_fraction)\n",
    "\n",
    "    cycle_refs = {}\n",
    "    cycle_spreads = {}\n",
    "    for cycle_id, idxs in groups.items():\n",
    "        idxs = [idx for idx in idxs if idx < len(stats)]\n",
    "        if not idxs:\n",
    "            continue\n",
    "        idxs_arr = np.array(idxs, dtype=int)\n",
    "        cycle_candidates = backgrounds[idxs_arr][ref_mask[idxs_arr]] if ref_mask[idxs_arr].any() else backgrounds[idxs_arr]\n",
    "        if cycle_candidates.size:\n",
    "            cycle_refs[cycle_id] = _histnorm_trimmed_median(cycle_candidates, drop_upper=drop_upper_fraction)\n",
    "        else:\n",
    "            cycle_refs[cycle_id] = global_ref\n",
    "        spread_vals = np.array([max(1.0, stats[i]['p95'] - stats[i]['p5']) for i in idxs], dtype=np.float64)\n",
    "        if ref_mask[idxs_arr].any():\n",
    "            spread_vals = np.array([max(1.0, stats[i]['p95'] - stats[i]['p5']) for i in idxs if ref_mask[i]], dtype=np.float64)\n",
    "        cycle_spreads[cycle_id] = _histnorm_trimmed_median(spread_vals, drop_upper=0.2) if spread_vals.size else 1.0\n",
    "\n",
    "    normalized = np.empty_like(fused_stack, dtype=np.uint16)\n",
    "    shifts = []\n",
    "    scales = []\n",
    "    af_flags = []\n",
    "\n",
    "    for stat in stats:\n",
    "        idx = stat['index']\n",
    "        cycle_id = stat['cycle']\n",
    "        name = stat['name']\n",
    "        ref = cycle_refs.get(cycle_id, global_ref)\n",
    "        af_flag = _histnorm_is_af_channel(name)\n",
    "        shift = float(ref - stat['bg'])\n",
    "        if af_flag and shift < 0:\n",
    "            shift *= (1.0 + float(af_extra_pull))\n",
    "        shift = float(np.clip(shift, -float(max_shift), float(max_shift)))\n",
    "        spread_val = max(1.0, stat['p95'] - stat['p5'])\n",
    "        scale = 1.0\n",
    "        if align_spread:\n",
    "            ref_spread = cycle_spreads.get(cycle_id, spread_val)\n",
    "            if spread_val > 0 and ref_spread > 0:\n",
    "                scale = float(np.clip(ref_spread / max(spread_val, 1.0), float(min_scale), float(max_scale)))\n",
    "        channel = fused_stack[idx].astype(np.float64, copy=False)\n",
    "        shifted = channel + shift\n",
    "        if align_spread:\n",
    "            shifted = (shifted - ref) * scale + ref\n",
    "        normalized[idx] = np.clip(shifted, 0, 65535).astype(np.uint16)\n",
    "        stat['applied_shift'] = shift\n",
    "        stat['applied_scale'] = scale\n",
    "        stat['is_af'] = af_flag\n",
    "        shifts.append(shift)\n",
    "        scales.append(scale)\n",
    "        af_flags.append(af_flag)\n",
    "\n",
    "    shifts = np.array(shifts, dtype=np.float64)\n",
    "    scales = np.array(scales, dtype=np.float64)\n",
    "\n",
    "    print()\n",
    "    print(f\"[INFO] Global background reference: {global_ref:.1f}\")\n",
    "    def _cycle_sort_key(val):\n",
    "        try:\n",
    "            return (0, int(val))\n",
    "        except (TypeError, ValueError):\n",
    "            return (1, str(val))\n",
    "    for cycle_id in sorted(cycle_refs.keys(), key=_cycle_sort_key):\n",
    "        print(f\"  Cycle {cycle_id}: ref={cycle_refs[cycle_id]:.1f}, spread={cycle_spreads.get(cycle_id, 0.0):.1f}\")\n",
    "\n",
    "    print()\n",
    "    preview = stats[:max(1, int(log_preview))]\n",
    "    for stat in preview:\n",
    "        print(\n",
    "            f\"  C{stat['index']:02d} ({stat['name']} | cycle {stat['cycle']}): \"\n",
    "            f\"bg {stat['bg']:.1f} -> shift {stat['applied_shift']:+.1f}, \"\n",
    "            f\"scale {stat['applied_scale']:.3f}{' [AF]' if stat['is_af'] else ''}\"\n",
    "        )\n",
    "\n",
    "    if output_path is None:\n",
    "        # OUTPUT IN AF_removal/-Ordner (dediziert, Pipeline-konform)\n",
    "        af_removal_dir = BASE_EXPORT / \"AF_removal\"\n",
    "        af_removal_dir.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        # Fixer Dateiname (kein Suffix-Chaos!)\n",
    "        output_path = af_removal_dir / \"fused_decon_AF_cleaned.ome.tif\"\n",
    "    else:\n",
    "        output_path = Path(output_path)\n",
    "        \n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata = {'axes': 'CYX'}\n",
    "    if resolved_names:\n",
    "        names = resolved_names[:normalized.shape[0]]\n",
    "        metadata.setdefault('Channel', {})['Name'] = names\n",
    "        fluor_list = []\n",
    "        for nm in names:\n",
    "            if '(' in nm and nm.strip().endswith(')'):\n",
    "                base, flav = nm.rsplit('(', 1)\n",
    "                fluor_list.append(flav.strip(') '))\n",
    "            else:\n",
    "                fluor_list.append('Unknown')\n",
    "        metadata['Channel']['Fluor'] = fluor_list\n",
    "    if px_meta:\n",
    "        pixels_meta = {}\n",
    "        for key in ('PhysicalSizeX', 'PhysicalSizeY', 'PhysicalSizeZ', 'PhysicalSizeXUnit', 'PhysicalSizeYUnit', 'PhysicalSizeZUnit'):\n",
    "            if key in px_meta and px_meta[key] is not None:\n",
    "                pixels_meta[key] = px_meta[key]\n",
    "        if pixels_meta:\n",
    "            metadata['Pixels'] = pixels_meta\n",
    "\n",
    "    print()\n",
    "    print(\"[SAVE] Writing OME-TIFF with histogram-normalized intensities\u00e2\u20ac\u00a6\")\n",
    "    tiff.imwrite(\n",
    "        str(output_path),\n",
    "        normalized,\n",
    "        ome=True,\n",
    "        bigtiff=True,\n",
    "        compression='zlib',\n",
    "        photometric='minisblack',\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "    size_gb = output_path.stat().st_size / (1024 ** 3)\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SUCCESS: Histogram normalization complete\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Output file:  {output_path}\")\n",
    "    print(f\"File size:    {size_gb:.2f} GB\")\n",
    "    print(f\"Channels:     {normalized.shape[0]}\")\n",
    "    print(f\"Image size:   {normalized.shape[1]} x {normalized.shape[2]} px\")\n",
    "    print(f\"Shift range:  {shifts.min():+.1f} \u00e2\u2020\u2019 {shifts.max():+.1f} (mean {shifts.mean():+.1f})\")\n",
    "    if align_spread and scales.size:\n",
    "        print(f\"Scale range:  {scales.min():.3f} \u00e2\u2020\u2019 {scales.max():.3f} (mean {scales.mean():.3f})\")\n",
    "    if any(af_flags):\n",
    "        af_shifts = [stat['applied_shift'] for stat in stats if stat.get('is_af')]\n",
    "        if af_shifts:\n",
    "            print(f\"AF channels:  mean shift {np.mean(af_shifts):+.1f}\")\n",
    "    print()\n",
    "    print(\"NEXT STEPS:\")\n",
    "    print(\"  1. \u00c3\u2013ffnen Sie die Datei in Napari oder QuPath und pr\u00c3\u00bcfen Sie die Hintergrundlevel\")\n",
    "    print(\"  2. Vergleichen Sie AF-Kan\u00c3\u00a4le vor/nach der Normalisierung\")\n",
    "\n",
    "    globals()['hist_norm_stack'] = normalized\n",
    "    globals()['hist_norm_stats'] = stats\n",
    "    globals()['hist_norm_output'] = output_path\n",
    "    globals()['IMG_PATH'] = str(output_path)\n",
    "    globals()['STACK'] = None\n",
    "    globals()['STACK_SRC'] = ''\n",
    "    print(f'[CONFIG] IMG_PATH aktualisiert -> {output_path}')\n",
    "    print('          (AF/ACE nutzen jetzt den histogramm-normalisierten Stack)')\n",
    "    return normalized, stats, output_path\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Pfad / Defaults ----------\n",
    "# ============================================================================\n",
    "# >>> PIPELINE-INTEGRATION: Liest automatisch aus spillover/-Ordner <<<\n",
    "# ============================================================================\n",
    "SAMPLE_ID = \"sample_004\"\n",
    "WORKSPACE_EXPORT_ROOT = Path(r\"C:\\Users\\researcher\\data\\Epoxy_CyNif\\Epoxy_CyNif\\data\\export\")\n",
    "BASE_EXPORT = WORKSPACE_EXPORT_ROOT / SAMPLE_ID\n",
    "\n",
    "# STRIKT: Nur spillover/-Verzeichnis akzeptieren (kein Fallback!)\n",
    "spillover_dir = BASE_EXPORT / \"spillover\"\n",
    "spillover_file = spillover_dir / \"fused_decon_spillover_corrected.ome.tif\"\n",
    "\n",
    "if not spillover_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"\u00e2\u009d\u0152 FEHLER: Spillover-korrigierter Stack nicht gefunden:\\n\"\n",
    "        f\"  Erwartet: {spillover_file}\\n\"\n",
    "        f\"  Bitte Part 2 (Spillover-Pipeline) ausf\u00c3\u00bchren.\"\n",
    "    )\n",
    "\n",
    "IMG_PATH = str(spillover_file)\n",
    "print(f\"[CONFIG] AF-Removal nutzt Spillover-Input: {IMG_PATH}\")\n",
    "\n",
    "# Globals setzen\n",
    "globals()[\"WORKSPACE_EXPORT_ROOT\"] = WORKSPACE_EXPORT_ROOT\n",
    "globals()[\"BASE_EXPORT\"] = BASE_EXPORT\n",
    "globals()[\"SAMPLE_ID\"] = SAMPLE_ID\n",
    "globals()[\"IMG_PATH\"] = IMG_PATH\n",
    "\n",
    "SAVE_ROOT_FALLBACK = os.path.join(tempfile.gettempdir(), \"MP_Previews\")\n",
    "STACK = None\n",
    "STACK_SRC = \"\"\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def _ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True); return p\n",
    "\n",
    "def _basename_no_ome(path):\n",
    "    return re.sub(r'\\.ome\\.tif$', '', os.path.basename(path), flags=re.I)\n",
    "\n",
    "def _safe_root(path_hint):\n",
    "    try:\n",
    "        _ensure_dir(path_hint)\n",
    "        tmp = os.path.join(path_hint, \"_t.tmp\")\n",
    "        with open(tmp, \"wb\") as f: f.write(b\"ok\")\n",
    "        os.remove(tmp)\n",
    "        return path_hint\n",
    "    except Exception:\n",
    "        _ensure_dir(SAVE_ROOT_FALLBACK)\n",
    "        return SAVE_ROOT_FALLBACK\n",
    "\n",
    "def p_stretch(x, p1=1.0, p2=99.5):\n",
    "    lo,hi = np.percentile(x, [p1,p2]); hi = max(hi, lo+1e-6)\n",
    "    return np.clip((x-lo)/(hi-lo), 0, 1)\n",
    "\n",
    "def write_png(fp, arr01):\n",
    "    arr = (np.clip(arr01, 0, 1)*255).astype(np.uint8)\n",
    "    Image.fromarray(arr).save(fp, format=\"PNG\")\n",
    "\n",
    "def _load_stack(path):\n",
    "    assert os.path.exists(path), f\"Datei nicht gefunden: {path}\"\n",
    "    if tiff is not None:\n",
    "        arr = tiff.imread(path)\n",
    "    else:\n",
    "        import imageio.v2 as iio\n",
    "        arr = iio.imread(path)\n",
    "    if arr.ndim == 2:\n",
    "        arr = arr[None, ...]\n",
    "    elif arr.ndim == 4:\n",
    "        if arr.shape[1] <= 16: arr = np.moveaxis(arr, 1, 0)\n",
    "        arr = arr[:, 0, :, :]\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "# ---------- CH-Harmonisierung ----------\n",
    "def channel_harmonize(stack, mode=\"p99\"):\n",
    "    m = str(mode).lower()\n",
    "    st = stack.astype(np.float32, copy=True)\n",
    "    if m in (\"off\", \"none\"):\n",
    "        return st\n",
    "    C = st.shape[0]\n",
    "    if m == \"p99\":\n",
    "        scales = [max(1e-6, np.percentile(st[c], 99.0)) for c in range(C)]\n",
    "        ref = float(np.median(scales))\n",
    "        for c in range(C):\n",
    "            st[c] *= ref / scales[c]\n",
    "        return st\n",
    "    if m == \"ace\":\n",
    "        params = ACE_PARAMS\n",
    "        out = np.empty_like(st, dtype=np.float32)\n",
    "        for c in range(C):\n",
    "            out[c] = ace_local_equalize(\n",
    "                st[c],\n",
    "                radii=params.get('radii'),\n",
    "                alpha=params.get('alpha', 6.0),\n",
    "                iterations=params.get('iterations', 1),\n",
    "                clip=params.get('clip'),\n",
    "                radius=params.get('radius'),\n",
    "                preserve_background=params.get('preserve_background', True),\n",
    "                max_gain=params.get('max_gain', 3.0)\n",
    "            )\n",
    "        return out\n",
    "    # default: IQR\n",
    "    scales = []\n",
    "    for c in range(C):\n",
    "        q1, q3 = np.percentile(st[c], [25.0, 75.0])\n",
    "        scales.append(max(1e-6, q3 - q1))\n",
    "    ref = float(np.median(scales))\n",
    "    for c in range(C):\n",
    "        st[c] *= ref / scales[c]\n",
    "    return st\n",
    "\n",
    "# ---------- robuste Statistik ----------\n",
    "def _mad(x):\n",
    "    med = np.median(x)\n",
    "    return 1.4826*np.median(np.abs(x - med))\n",
    "\n",
    "# ---------- Huber-IRLS (robust) f\u00c3\u00bcr 2 Donoren ----------\n",
    "def huber_ridge_2d(C2, C3, Y, lam=1e-3, delta=1.5, iters=5):\n",
    "    x1 = C2.ravel(); x2 = C3.ravel(); y = Y.ravel()\n",
    "    X = np.stack([x1, x2], 1).astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "    XtX = X.T @ X + lam*np.eye(2, dtype=np.float32)\n",
    "    Xty = X.T @ y\n",
    "    w = np.linalg.lstsq(XtX, Xty, rcond=None)[0]\n",
    "    for _ in range(max(1,iters)):\n",
    "        r = y - X @ w\n",
    "        s = _mad(r) + 1e-6\n",
    "        t = delta * s\n",
    "        a = np.abs(r)\n",
    "        w_i = np.ones_like(a, dtype=np.float32)\n",
    "        mask = (a > t)\n",
    "        w_i[mask] = (t / a[mask]).astype(np.float32)\n",
    "        XtWX = X.T @ (X*w_i[:,None]) + lam*np.eye(2, dtype=np.float32)\n",
    "        XtWy = X.T @ (y*w_i)\n",
    "        w = np.linalg.lstsq(XtWX, XtWy, rcond=None)[0]\n",
    "    return w  # ENTFERNT: np.maximum(0.0, w) - Erlaube negative Gewichte wenn statistisch optimal\n",
    "\n",
    "# ---------- Lokale Statistiken ----------\n",
    "def local_mean_std(img, win=15):\n",
    "    win = int(max(3, win))\n",
    "    mu = ndi.uniform_filter(img, size=win, mode='reflect')\n",
    "    mu2 = ndi.uniform_filter(img*img, size=win, mode='reflect')\n",
    "    var = np.maximum(0.0, mu2 - mu*mu)\n",
    "    return mu, np.sqrt(var + 1e-6)\n",
    "\n",
    "def masked_local_mean_std(img, mask, win=15):\n",
    "    win = int(max(3, win))\n",
    "    k = np.ones((win, win), np.float32)\n",
    "    inv = (~mask).astype(np.float32)\n",
    "    sum_ = ndi.convolve(img * inv, k, mode='reflect')\n",
    "    cnt  = ndi.convolve(inv,      k, mode='reflect')\n",
    "    mu   = sum_ / np.maximum(1.0, cnt)\n",
    "    sum2 = ndi.convolve((img * inv)**2, k, mode='reflect')\n",
    "    var  = np.maximum(0.0, sum2/np.maximum(1.0, cnt) - mu*mu)\n",
    "    return mu, np.sqrt(var + 1e-6)\n",
    "\n",
    "def ring_mean_std(mask, img, band=5, win=15):\n",
    "    band = int(max(1, band)); win = int(max(3, win))\n",
    "    ring = morph.binary_dilation(mask, footprint=disk(band)) & (~mask)\n",
    "    if not ring.any():\n",
    "        return local_mean_std(img, win=win)\n",
    "    vals = img[ring]\n",
    "    mu_ring = np.median(vals); sd_ring = 1.4826*np.median(np.abs(vals - mu_ring))\n",
    "    mu = np.full_like(img, float(mu_ring), dtype=np.float32)\n",
    "    sd = np.full_like(img, float(sd_ring)+1e-6, dtype=np.float32)\n",
    "    return mu, sd\n",
    "\n",
    "# ---------- GenFill(exp): multiskaliger Grain um Anchor-Statistik ----------\n",
    "def genfill_exp_fill(tgt, mask, mu_loc, sd_loc, anchor_bias_sd=0.20, feather_px=6,\n",
    "                     beta=0.5, octaves=4, base_sigma=1.2, seed=123):\n",
    "    rng = np.random.default_rng(int(seed))\n",
    "    H,W = tgt.shape\n",
    "    anchor = np.maximum(0.0, mu_loc - float(anchor_bias_sd)*sd_loc)\n",
    "    anchor = np.minimum(anchor, tgt)\n",
    "    noise = np.zeros_like(tgt, dtype=np.float32)\n",
    "    sig = float(base_sigma)\n",
    "    for k in range(int(max(1,octaves))):\n",
    "        z = rng.standard_normal(size=(H,W)).astype(np.float32)\n",
    "        nz = ndi.gaussian_filter(z, sigma=sig, mode='reflect')\n",
    "        nz = nz / (np.std(nz) + 1e-6)\n",
    "        noise += nz / (2.0**k)\n",
    "        sig *= 1.7\n",
    "    noise = noise / (np.std(noise) + 1e-6)\n",
    "    grain = anchor + float(beta)*sd_loc*np.clip(noise, -2.5, 2.5)\n",
    "    grain = np.minimum(grain, tgt)\n",
    "    out = tgt.copy()\n",
    "    if int(feather_px) > 0:\n",
    "        di = ndi.distance_transform_edt(mask)\n",
    "        w_blend = np.clip(di / float(feather_px), 0.0, 1.0)\n",
    "        mix = (1.0 - w_blend)*out + w_blend*grain\n",
    "        out[mask] = mix[mask]\n",
    "    else:\n",
    "        out[mask] = grain[mask]\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_background_estimate(tgt, mask, sigma=0.0):\n",
    "    mask_bool = mask.astype(bool, copy=False)\n",
    "    if not mask_bool.any():\n",
    "        return tgt\n",
    "    inv = (~mask_bool).astype(np.float32)\n",
    "    if inv.sum() == 0:\n",
    "        return tgt\n",
    "    tgt_f = tgt.astype(np.float32, copy=False)\n",
    "    if sigma is None or sigma <= 0:\n",
    "        sigma = max(1.0, 0.01 * np.hypot(*tgt.shape))\n",
    "    numer = ndi.gaussian_filter(tgt_f * inv, sigma=sigma, mode='reflect')\n",
    "    denom = ndi.gaussian_filter(inv, sigma=sigma, mode='reflect')\n",
    "    bg = np.where(denom > 1e-3, numer / (denom + 1e-6), tgt_f)\n",
    "    return bg\n",
    "\n",
    "def blended_fill(tgt, fill, mask, feather_px=0, softness=1.0):\n",
    "    mask_bool = mask.astype(bool, copy=False)\n",
    "    if not mask_bool.any():\n",
    "        return tgt\n",
    "    out = tgt.copy()\n",
    "    if feather_px is None or feather_px <= 0:\n",
    "        out[mask_bool] = fill[mask_bool]\n",
    "        return out\n",
    "    dist = ndi.distance_transform_edt(mask_bool)\n",
    "    w = np.clip(dist / float(feather_px), 0.0, 1.0)\n",
    "    if softness and softness > 0:\n",
    "        w = np.power(w, 1.0 / float(softness))\n",
    "    out[mask_bool] = w[mask_bool] * fill[mask_bool] + (1.0 - w[mask_bool]) * tgt[mask_bool]\n",
    "    return out\n",
    "\n",
    "# ---------- Epoxy_CyNif-AF auf ROI ----------\n",
    "def Epoxy_CyNif_af_roi(\n",
    "    stack, target, roi_xywh,\n",
    "    ch_mode=\"p99\",\n",
    "    donor_sigma=1.6,\n",
    "    kmad=5.5,\n",
    "    mask_erode_px=0,\n",
    "    mask_close_px=0,\n",
    "    mask_expand_px=0,\n",
    "    huber_delta=2.5,\n",
    "    ridge_lambda=1e-4,\n",
    "    cap_kappa=1.8,\n",
    "    cap_win=15,\n",
    "    closing_r=2,\n",
    "    median_k=3,\n",
    "    viz=\"Auto\",\n",
    "    pred_gain=1.35,\n",
    "    cap_mode=\"anchor_strict\",      # \"local\"|\"ring\"|\"hybrid\"|\"anchor\"|\"anchor_strict\"\n",
    "    ring_band_px=5,\n",
    "    donor_pow=1.10,\n",
    "    anchor_bias_sd=0.05,\n",
    "    feather_px=0,\n",
    "    genfill_on=False,\n",
    "    gen_beta=0.5,\n",
    "    gen_octaves=4,\n",
    "    gen_base_sigma=1.2,\n",
    "    gen_seed=123\n",
    "):\n",
    "    st = channel_harmonize(stack, ch_mode)\n",
    "    C,H,W = st.shape\n",
    "    x,y,w,h = roi_xywh; x1,y1 = x+w, y+h\n",
    "    def R(c): return st[int(np.clip(c,0,C-1)), y:y1, x:x1].astype(np.float32).copy()\n",
    "\n",
    "    tgt = R(target); c2 = R(1); c3 = R(2)\n",
    "\n",
    "    if donor_sigma>0: c2s=ndi.gaussian_filter(c2, donor_sigma); c3s=ndi.gaussian_filter(c3, donor_sigma)\n",
    "    else: c2s, c3s = c2, c3\n",
    "    if abs(donor_pow-1.0)>1e-3:\n",
    "        c2s=np.power(np.maximum(0.0,c2s), donor_pow); c3s=np.power(np.maximum(0.0,c3s), donor_pow)\n",
    "    dsum = c2s + c3s\n",
    "\n",
    "    med = np.median(dsum); mad = _mad(dsum); thr = med + kmad*mad\n",
    "    mask = (dsum > thr)\n",
    "    if mask_erode_px>0:  mask = morph.binary_erosion(mask, footprint=disk(int(mask_erode_px)))\n",
    "    if mask_close_px>0:  mask = morph.binary_closing(mask, footprint=disk(int(mask_close_px)))\n",
    "    if mask_expand_px>0: mask = morph.binary_dilation(mask, footprint=disk(int(mask_expand_px)))\n",
    "\n",
    "    if np.any(mask):\n",
    "        wts = huber_ridge_2d(c2s[mask], c3s[mask], tgt[mask], lam=ridge_lambda, delta=huber_delta, iters=5)\n",
    "        pred = wts[0]*c2s + wts[1]*c3s\n",
    "        raw_sub = tgt - pred_gain*pred\n",
    "\n",
    "        mu_loc, sd_loc   = masked_local_mean_std(tgt, mask, win=int(cap_win))\n",
    "        mu_ring, sd_ring = ring_mean_std(mask, tgt, band=int(ring_band_px), win=int(cap_win))\n",
    "        cap_local = mu_loc + cap_kappa*sd_loc\n",
    "        cap_ring  = mu_ring + cap_kappa*sd_ring\n",
    "\n",
    "        cm = str(cap_mode).lower()\n",
    "        if cm in (\"anchor\",\"anchor_strict\"):\n",
    "            bias = float(anchor_bias_sd) if anchor_bias_sd is not None else 0.0\n",
    "            anchor = np.maximum(0.0, mu_loc - bias*sd_loc)\n",
    "            anchor = np.minimum(anchor, tgt)\n",
    "            if genfill_on:\n",
    "                clean = genfill_exp_fill(\n",
    "                    tgt, mask, mu_loc, sd_loc,\n",
    "                    anchor_bias_sd=float(anchor_bias_sd),\n",
    "                    feather_px=int(feather_px),\n",
    "                    beta=float(gen_beta),\n",
    "                    octaves=int(gen_octaves),\n",
    "                    base_sigma=float(gen_base_sigma),\n",
    "                    seed=int(gen_seed)\n",
    "                )\n",
    "            else:\n",
    "                base = np.maximum(raw_sub, 0.0)\n",
    "                clean = tgt.copy()\n",
    "                if int(feather_px) > 0:\n",
    "                    di = ndi.distance_transform_edt(mask)\n",
    "                    w_blend = np.clip(di/float(feather_px), 0.0, 1.0)\n",
    "                    mix = (1.0 - w_blend)*base + w_blend*anchor\n",
    "                    clean[mask] = np.minimum(mix[mask], tgt[mask])\n",
    "                else:\n",
    "                    # HARTER SCHNITT: Erweitere Maske um 2px und setze auf 0.0\n",
    "                    mask_expanded = morph.binary_dilation(mask, footprint=disk(2))\n",
    "                    clean[mask_expanded] = 0.0\n",
    "        else:\n",
    "            if cm == \"ring\":\n",
    "                cap = cap_ring\n",
    "            elif cm == \"hybrid\":\n",
    "                cap = np.minimum(cap_local, cap_ring)\n",
    "            elif cm == \"local\":\n",
    "                cap = cap_local\n",
    "            else:\n",
    "                cap = np.minimum(cap_local, tgt)\n",
    "            base = np.maximum(raw_sub, 0.0)\n",
    "            clean = tgt.copy()\n",
    "            clean[mask] = np.maximum(base[mask], cap[mask])\n",
    "            clean = np.clip(clean, 0, None)\n",
    "    else:\n",
    "        wts=np.array([0.0,0.0],np.float32); pred=np.zeros_like(tgt); clean=tgt.copy()\n",
    "\n",
    "    # Post-Processing: closing/median NUR au\u00c3\u0178erhalb der erweiterten AF-Maske anwenden\n",
    "    # um den harten Rand nicht wieder zu gl\u00c3\u00a4tten\n",
    "    if np.any(mask):\n",
    "        mask_expanded = morph.binary_dilation(mask, footprint=disk(2))\n",
    "        temp_clean = clean.copy()\n",
    "        \n",
    "        if closing_r>0: \n",
    "            temp_clean = ndi.grey_closing(temp_clean, size=(int(closing_r), int(closing_r)))\n",
    "        if median_k>1:  \n",
    "            temp_clean = ndi.median_filter(temp_clean, size=int(median_k))\n",
    "        \n",
    "        # \u00c3\u0153bernehme gefilterte Werte nur au\u00c3\u0178erhalb der AF-Zone\n",
    "        clean[~mask_expanded] = temp_clean[~mask_expanded]\n",
    "    else:\n",
    "        # Kein AF gefunden: normale Filter anwenden\n",
    "        if closing_r>0: clean = ndi.grey_closing(clean, size=(int(closing_r), int(closing_r)))\n",
    "        if median_k>1:  clean = ndi.median_filter(clean, size=int(median_k))\n",
    "\n",
    "    if viz==\"Auto\": M=lambda z:p_stretch(z)\n",
    "    else:\n",
    "        lo,hi=np.percentile(tgt,[1.0,99.5]); hi=max(hi,lo+1e-6); M=lambda z:np.clip((z-lo)/(hi-lo),0,1)\n",
    "\n",
    "    panel = dict(raw=M(tgt), c2=M(c2), c3=M(c3), dsum=M(dsum), mask=mask.astype(np.float32), pred=M(pred), clean=M(clean))\n",
    "    meta  = dict(\n",
    "        tgt_idx=int(target), ch_mode=str(ch_mode), viz=str(viz),\n",
    "        donor_sigma=float(donor_sigma), kmad=float(kmad),\n",
    "        mask_erode_px=int(mask_erode_px), mask_close_px=int(mask_close_px), mask_expand_px=int(mask_expand_px),\n",
    "        huber_delta=float(huber_delta), ridge_lambda=float(ridge_lambda),\n",
    "        cap_kappa=float(cap_kappa), cap_win=int(cap_win),\n",
    "        closing_r=int(closing_r), median_k=int(median_k),\n",
    "        pred_gain=float(pred_gain), cap_mode=str(cap_mode),\n",
    "        ring_band_px=int(ring_band_px), donor_pow=float(donor_pow),\n",
    "        anchor_bias_sd=float(anchor_bias_sd), feather_px=int(feather_px),\n",
    "        genfill_on=bool(genfill_on), gen_beta=float(gen_beta), gen_octaves=int(gen_octaves),\n",
    "        gen_base_sigma=float(gen_base_sigma), gen_seed=int(gen_seed),\n",
    "        weights={'w_c2':float(wts[0]), 'w_c3':float(wts[1])},\n",
    "        mask_pct=100.0*float(mask.sum())/max(1,mask.size)\n",
    "    )\n",
    "    return dict(panel=panel, meta=meta)\n",
    "\n",
    "# ---------- ZIP-Speicher (robust: k\u00c3\u00bcrzer + Fallback in %TEMP%) ----------\n",
    "def _meta_fingerprint(meta: dict) -> str:\n",
    "    sig = {k: meta.get(k) for k in [\n",
    "        'tgt_idx','kmad','mask_erode_px','mask_close_px','mask_expand_px','donor_sigma','huber_delta','ridge_lambda',\n",
    "        'cap_kappa','cap_win','pred_gain','cap_mode','ring_band_px','donor_pow','anchor_bias_sd','feather_px',\n",
    "        'genfill_on','gen_beta','gen_octaves','gen_base_sigma'\n",
    "    ]}\n",
    "    s = json.dumps(sig, sort_keys=True).encode('utf-8')\n",
    "    return hashlib.md5(s).hexdigest()[:8]\n",
    "\n",
    "def save_preview_zip(panel, meta, img_path, roi_xywh, tag=\"Epoxy_CyNif_AF\"):\n",
    "    base_long = f\"{_basename_no_ome(img_path)}_x{roi_xywh[0]}_y{roi_xywh[1]}_s{roi_xywh[2]}\"\n",
    "    root_hint = os.path.join(os.path.dirname(img_path), \"MP_Previews\")\n",
    "    root = _safe_root(root_hint)\n",
    "    base = re.sub(r'[^A-Za-z0-9_\\-]', '_', base_long)\n",
    "    if len(base) > 48: base = base[:48]\n",
    "    prev_dir = _ensure_dir(os.path.join(root, base))\n",
    "    finger   = _meta_fingerprint(meta)\n",
    "    ts       = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "    fname    = f\"{base}_C{meta['tgt_idx']}_{str(tag)[:14]}_{finger}_{ts}.zip\"\n",
    "    zpath    = os.path.join(prev_dir, fname)\n",
    "\n",
    "    def _write_zip(to_path):\n",
    "        tmpfiles = []\n",
    "        try:\n",
    "            for k in [\"raw\",\"c2\",\"c3\",\"dsum\",\"mask\",\"pred\",\"clean\"]:\n",
    "                fp = os.path.join(prev_dir, f\"{k}.png\")\n",
    "                write_png(fp, panel[k]); tmpfiles.append((k+\".png\", fp))\n",
    "            mfp = os.path.join(prev_dir, \"meta.json\")\n",
    "            with open(mfp, \"w\", encoding=\"utf-8\") as f: json.dump(meta, f, indent=2)\n",
    "            _ensure_dir(os.path.dirname(to_path))\n",
    "            with zipfile.ZipFile(to_path, 'w', compression=zipfile.ZIP_DEFLATED) as Z:\n",
    "                for arc,fp in tmpfiles: Z.write(fp, arcname=arc)\n",
    "                Z.write(mfp, arcname=\"meta.json\")\n",
    "            return to_path\n",
    "        finally:\n",
    "            for _,fp in tmpfiles:\n",
    "                try: os.remove(fp)\n",
    "                except: pass\n",
    "            try: os.remove(mfp)\n",
    "            except: pass\n",
    "\n",
    "    try:\n",
    "        return _write_zip(zpath)\n",
    "    except Exception:\n",
    "        pass\n",
    "    temp_root = _ensure_dir(os.path.join(tempfile.gettempdir(), \"MP_Previews\"))\n",
    "    prev_dir2 = _ensure_dir(os.path.join(temp_root, base[:24]))\n",
    "    zpath2    = os.path.join(prev_dir2, f\"prev_{finger}_{ts}.zip\")\n",
    "    return _write_zip(zpath2)\n",
    "\n",
    "# ---------- UI ----------\n",
    "def _build_ui():\n",
    "    global STACK, STACK_SRC, IMG_PATH, ACE_PARAMS\n",
    "\n",
    "    w_path = widgets.Text(value=IMG_PATH, description=\"OME-TIF:\", layout=widgets.Layout(width='100%'))\n",
    "    w_load = widgets.Button(description=\"Load\", button_style='info', tooltip=\"Bildstapel laden\")\n",
    "    w_over = widgets.Button(description=\"Show Overview\", button_style='info', tooltip=\"\u00c3\u0153bersicht & ROI (klicken)\")\n",
    "\n",
    "    w_tgt  = widgets.BoundedIntText(value=3, min=0, max=63, description=\"Target C (Index)\")\n",
    "    w_x    = widgets.BoundedIntText(value=1696, min=0, max=50000, description=\"x\")\n",
    "    w_y    = widgets.BoundedIntText(value=4528, min=0, max=50000, description=\"y\")\n",
    "    w_s    = widgets.BoundedIntText(value=384,  min=64, max=4096, description=\"size\")\n",
    "\n",
    "    w_ch   = widgets.Dropdown(options=[\"p99\",\"IQR\",\"ACE\",\"Off\"], value=\"ACE\", description=\"CH (Harmonize)\")\n",
    "    w_viz  = widgets.Dropdown(options=[\"Auto\",\"Fixed\"], value=\"Auto\", description=\"Viz\")\n",
    "    w_ace_alpha = widgets.FloatSlider(value=float(ACE_PARAMS.get('alpha', 6.0)), min=1.0, max=15.0, step=0.5, description=\"ACE \u00ce\u00b1\")\n",
    "    w_ace_radius = widgets.IntSlider(value=int(ACE_PARAMS.get('radius', 0) or 0), min=0, max=512, step=16, description=\"ACE Radius\", tooltip=\"0 = global\")\n",
    "    w_ace_gain = widgets.FloatSlider(value=float(ACE_PARAMS.get('max_gain', 3.0)), min=1.0, max=5.0, step=0.1, description=\"ACE gain cap\")\n",
    "\n",
    "    # Basis-Parameter\n",
    "    w_sig  = widgets.FloatSlider(value=1.6, min=0.0, max=3.0, step=0.1, description=\"Donor blur (\u00cf\u0192)\")\n",
    "    w_kmad = widgets.FloatSlider(value=5.5, min=2.0, max=12.0, step=0.5, description=\"AF detect (k\u00c2\u00b7MAD)\")\n",
    "    w_er   = widgets.IntSlider(value=0, min=0, max=5, step=1, description=\"Mask shrink (erode px)\")\n",
    "    w_cloM = widgets.IntSlider(value=0, min=0, max=7, step=1, description=\"Mask close (px)\")\n",
    "    w_dil  = widgets.IntSlider(value=1, min=0, max=12, step=1, description=\"Mask grow (dilate px)\")\n",
    "\n",
    "    w_hub  = widgets.FloatSlider(value=2.5, min=0.5, max=4.0, step=0.1, description=\"Robust fit (Huber \u00ce\u00b4)\")\n",
    "    w_lam  = widgets.FloatLogSlider(value=1e-4, base=10, min=-6, max=-1, step=0.25, description=\"Weight L2 (\u00ce\u00bb)\")\n",
    "    w_ck   = widgets.FloatSlider(value=1.8, min=0.0, max=6.0, step=0.1, description=\"Clamp softness (\u00ce\u00ba)\")\n",
    "    w_cw   = widgets.IntSlider(value=15, min=5, max=31, step=2, description=\"Clamp window (px)\")\n",
    "    w_clos = widgets.IntSlider(value=2, min=0, max=9, step=1, description=\"Post smooth (closing r)\")\n",
    "    w_med  = widgets.IntSlider(value=3, min=1, max=7, step=2, description=\"Post noise (median k)\")\n",
    "\n",
    "    # Patches + Anchor\n",
    "    w_gain = widgets.FloatSlider(value=1.35, min=1.0, max=2.2, step=0.05, description=\"Donor gain (\u00ce\u00b3)\")\n",
    "    w_cmode= widgets.Dropdown(options=[\"local\",\"hybrid\",\"ring\",\"anchor\",\"anchor_strict\"], value=\"anchor\", description=\"Fill mode\")\n",
    "    w_ring = widgets.IntSlider(value=5, min=1, max=15, step=1, description=\"Ring width (px)\")\n",
    "    w_pow  = widgets.FloatSlider(value=1.10, min=0.8, max=1.5, step=0.02, description=\"Donor exponent (p)\")\n",
    "    w_bias = widgets.FloatSlider(value=0.15, min=0.00, max=0.50, step=0.01, description=\"Anchor bias (\u00c3\u2014\u00cf\u0192)\")\n",
    "    w_fth  = widgets.IntSlider(value=3, min=0, max=12, step=1, description=\"Feather (px)\")\n",
    "\n",
    "    # GenFill(exp)\n",
    "    w_gf_on   = widgets.Checkbox(value=False, description=\"GenFill (exp) on\")\n",
    "    w_gf_beta = widgets.FloatSlider(value=0.50, min=0.0, max=1.0, step=0.05, description=\"GenFill strength (\u00ce\u00b2)\")\n",
    "    w_gf_oct  = widgets.IntSlider(value=4, min=1, max=6, step=1, description=\"GenFill octaves\")\n",
    "    w_gf_sig  = widgets.FloatSlider(value=1.2, min=0.6, max=2.5, step=0.1, description=\"GenFill base \u00cf\u0192\")\n",
    "    w_gf_seed = widgets.IntText(value=123, description=\"GenFill seed\")\n",
    "\n",
    "    def _update_ace_params(change=None):\n",
    "        ACE_PARAMS[\"alpha\"] = float(w_ace_alpha.value)\n",
    "        ACE_PARAMS[\"radius\"] = int(w_ace_radius.value) if int(w_ace_radius.value) > 0 else None\n",
    "        ACE_PARAMS[\"max_gain\"] = float(w_ace_gain.value)\n",
    "        ACE_PARAMS[\"post_enabled\"] = bool(w_ace_post.value)\n",
    "\n",
    "    # --- NEU: Settings-Zeile laden ---\n",
    "    w_txt = widgets.Text(\n",
    "        value=\"\",\n",
    "        placeholder=\"kmad=4.5 grow=8 close=2 bias=0.35 feather=3 mode=anchor_strict gen=on gbeta=0.5 goct=4 gsig=1.2 gain=1.45\",\n",
    "        description=\"Settings:\"\n",
    "    )\n",
    "    btn_apply = widgets.Button(description=\"Apply settings\", button_style='warning', tooltip=\"Zeile parsen & Regler setzen\")\n",
    "\n",
    "    btn_run   = widgets.Button(description=\"RUN Preview\", button_style='success')\n",
    "    btn_zip   = widgets.Button(description=\"Save Preview ZIP\", button_style='warning')\n",
    "\n",
    "    out_over  = widgets.Output()\n",
    "    out_panel = widgets.Output()\n",
    "    out_info  = widgets.Output(layout=widgets.Layout(height='360px'))\n",
    "\n",
    "    def _ensure_loaded():\n",
    "        global STACK, STACK_SRC, IMG_PATH\n",
    "        IMG_PATH = w_path.value\n",
    "        if (STACK is None) or (STACK_SRC != IMG_PATH):\n",
    "            with out_info: print(\"\u00e2\u20ac\u00a2 Lade Stack\u00e2\u20ac\u00a6\", IMG_PATH)\n",
    "            st = _load_stack(IMG_PATH)\n",
    "            STACK = st; STACK_SRC = IMG_PATH\n",
    "            C,H,W = st.shape\n",
    "            w_tgt.max = max(0, C-1)\n",
    "            w_x.max   = max(0, W-64)\n",
    "            w_y.max   = max(0, H-64)\n",
    "            with out_info:\n",
    "                print(f\"\u00e2\u0153\u201d Geladen. Shape (C,H,W)={STACK.shape}\")\n",
    "                print(\"Spickzettel f\u00c3\u00bcr Settings-Zeile:\")\n",
    "                print(\"  kmad=\u00e2\u20ac\u00a6 grow=\u00e2\u20ac\u00a6 close=\u00e2\u20ac\u00a6 erode=\u00e2\u20ac\u00a6 bias=\u00e2\u20ac\u00a6 feather=\u00e2\u20ac\u00a6 mode=anchor|anchor_strict|local|hybrid|ring\")\n",
    "                print(\"  gen=on|off gbeta=\u00e2\u20ac\u00a6 goct=\u00e2\u20ac\u00a6 gsig=\u00e2\u20ac\u00a6 gain=\u00e2\u20ac\u00a6 ring=\u00e2\u20ac\u00a6 cwin=\u00e2\u20ac\u00a6 ck=\u00e2\u20ac\u00a6 sig=\u00e2\u20ac\u00a6 pow=\u00e2\u20ac\u00a6\")\n",
    "                print(\"  ch=p99|IQR|ACE|Off viz=Auto|Fixed tgt=3 x=1696 y=4528 s=384\")\n",
    "\n",
    "    def on_over(ev=None):\n",
    "        out_over.clear_output(True)\n",
    "        try:\n",
    "            _ensure_loaded()\n",
    "            st = channel_harmonize(STACK, w_ch.value)\n",
    "            img = st[int(w_tgt.value)]\n",
    "            H,W = img.shape\n",
    "            ds = max(1, int(np.ceil(max(H,W)/1100)))\n",
    "            view = img[::ds, ::ds]\n",
    "            fig, ax = plt.subplots(figsize=(22,7))\n",
    "            ax.imshow(p_stretch(view), cmap='gray'); ax.axis('off')\n",
    "            ax.set_title(\"Overview \u00e2\u20ac\u201d Klick setzt ROI\")\n",
    "            s = int(w_s.value); x = int(w_x.value)//ds; y = int(w_y.value)//ds\n",
    "            rect = Rectangle((x,y), s//ds, s//ds, fill=False, edgecolor='lime', linewidth=2)\n",
    "            ax.add_patch(rect)\n",
    "            def onclick(event):\n",
    "                if not event.inaxes: return\n",
    "                cx, cy = int(event.xdata)*ds, int(event.ydata)*ds\n",
    "                S = int(w_s.value)\n",
    "                nx = int(np.clip(cx - S//2, 0, max(0, W - S)))\n",
    "                ny = int(np.clip(cy - S//2, 0, max(0, H - S)))\n",
    "                w_x.value, w_y.value = nx, ny\n",
    "                rect.set_xy((nx//ds, ny//ds)); fig.canvas.draw_idle()\n",
    "            fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "            with out_over: display(fig); plt.close(fig)\n",
    "        except Exception as e:\n",
    "            with out_info: print(\"\u00e2\u0153\u2013 Overview-Fehler:\", e); traceback.print_exc()\n",
    "\n",
    "    # ---- Settings-Zeile parsen & anwenden ----\n",
    "    def _parse_bool(v):\n",
    "        return str(v).strip().lower() in (\"1\",\"true\",\"on\",\"yes\",\"y\")\n",
    "\n",
    "    def on_apply(ev=None):\n",
    "        line = w_txt.value.strip()\n",
    "        if not line:\n",
    "            with out_info: print(\"\u00e2\u201e\u00b9 Keine Settings-Zeile eingegeben.\")\n",
    "            return\n",
    "        # Key-Map: alias -> (widget, type)\n",
    "        m = {\n",
    "            # ROI / Ziel\n",
    "            \"tgt\": (\"w_tgt\",\"int\"), \"target\": (\"w_tgt\",\"int\"),\n",
    "            \"x\": (\"w_x\",\"int\"), \"y\": (\"w_y\",\"int\"), \"s\": (\"w_s\",\"int\"), \"size\": (\"w_s\",\"int\"),\n",
    "            # CH / Viz\n",
    "            \"ch\": (\"w_ch\",\"str\"), \"harm\": (\"w_ch\",\"str\"),\n",
    "            \"viz\": (\"w_viz\",\"str\"),\n",
    "            # Detection / Maske\n",
    "            \"kmad\": (\"w_kmad\",\"float\"),\n",
    "            \"erode\": (\"w_er\",\"int\"), \"shrink\": (\"w_er\",\"int\"),\n",
    "            \"close\": (\"w_cloM\",\"int\"),\n",
    "            \"grow\": (\"w_dil\",\"int\"), \"dilate\": (\"w_dil\",\"int\"),\n",
    "            # Donor\n",
    "            \"sig\": (\"w_sig\",\"float\"), \"sigma\": (\"w_sig\",\"float\"), \"donor_sigma\": (\"w_sig\",\"float\"),\n",
    "            \"pow\": (\"w_pow\",\"float\"), \"donor_pow\": (\"w_pow\",\"float\"),\n",
    "            # Robust / Regular\n",
    "            \"huber\": (\"w_hub\",\"float\"), \"delta\": (\"w_hub\",\"float\"),\n",
    "            \"lam\": (\"w_lam\",\"float\"), \"lambda\": (\"w_lam\",\"float\"), \"ridge\": (\"w_lam\",\"float\"),\n",
    "            # Clamp\n",
    "            \"ck\": (\"w_ck\",\"float\"), \"kappa\": (\"w_ck\",\"float\"), \"cap_kappa\": (\"w_ck\",\"float\"),\n",
    "            \"cwin\": (\"w_cw\",\"int\"), \"win\": (\"w_cw\",\"int\"), \"cap_win\": (\"w_cw\",\"int\"),\n",
    "            \"closing\": (\"w_clos\",\"int\"), \"post_close\": (\"w_clos\",\"int\"), \"closing_r\": (\"w_clos\",\"int\"),\n",
    "            \"median\": (\"w_med\",\"int\"), \"med\": (\"w_med\",\"int\"), \"median_k\": (\"w_med\",\"int\"),\n",
    "            # Fill / Anchor\n",
    "            \"gain\": (\"w_gain\",\"float\"), \"pred_gain\": (\"w_gain\",\"float\"), \"gamma\": (\"w_gain\",\"float\"),\n",
    "            \"mode\": (\"w_cmode\",\"str\"), \"cap_mode\": (\"w_cmode\",\"str\"),\n",
    "            \"ring\": (\"w_ring\",\"int\"), \"ring_band\": (\"w_ring\",\"int\"),\n",
    "            \"bias\": (\"w_bias\",\"float\"), \"anchor_bias_sd\": (\"w_bias\",\"float\"),\n",
    "            \"feather\": (\"w_fth\",\"int\"), \"feather_px\": (\"w_fth\",\"int\"),\n",
    "            # GenFill\n",
    "            \"gen\": (\"w_gf_on\",\"bool\"), \"genfill\": (\"w_gf_on\",\"bool\"),\n",
    "            \"gbeta\": (\"w_gf_beta\",\"float\"), \"gen_beta\": (\"w_gf_beta\",\"float\"),\n",
    "            \"goct\": (\"w_gf_oct\",\"int\"), \"gen_oct\": (\"w_gf_oct\",\"int\"),\n",
    "            \"gsig\": (\"w_gf_sig\",\"float\"), \"gen_sigma\": (\"w_gf_sig\",\"float\"), \"gen_base_sigma\": (\"w_gf_sig\",\"float\"),\n",
    "            \"gseed\": (\"w_gf_seed\",\"int\"), \"seed\": (\"w_gf_seed\",\"int\"),\n",
    "        }\n",
    "        # Name -> Widget Objekt\n",
    "        W = {\n",
    "            \"w_tgt\": w_tgt, \"w_x\": w_x, \"w_y\": w_y, \"w_s\": w_s,\n",
    "            \"w_ch\": w_ch, \"w_viz\": w_viz,\n",
    "            \"w_kmad\": w_kmad, \"w_er\": w_er, \"w_cloM\": w_cloM, \"w_dil\": w_dil,\n",
    "            \"w_sig\": w_sig, \"w_pow\": w_pow, \"w_hub\": w_hub, \"w_lam\": w_lam,\n",
    "            \"w_ck\": w_ck, \"w_cw\": w_cw, \"w_clos\": w_clos, \"w_med\": w_med,\n",
    "            \"w_gain\": w_gain, \"w_cmode\": w_cmode, \"w_ring\": w_ring,\n",
    "            \"w_bias\": w_bias, \"w_fth\": w_fth,\n",
    "            \"w_gf_on\": w_gf_on, \"w_gf_beta\": w_gf_beta, \"w_gf_oct\": w_gf_oct,\n",
    "            \"w_gf_sig\": w_gf_sig, \"w_gf_seed\": w_gf_seed\n",
    "        }\n",
    "        # Tokenize\n",
    "        changes = []\n",
    "        tokens = [t for t in re.split(r'\\s+', line) if t]\n",
    "        for tok in tokens:\n",
    "            if '=' not in tok: continue\n",
    "            k,v = tok.split('=',1)\n",
    "            k = k.strip().lower(); v = v.strip()\n",
    "            if k not in m: \n",
    "                continue\n",
    "            wname, typ = m[k]\n",
    "            ww = W[wname]\n",
    "            try:\n",
    "                if typ == \"int\":\n",
    "                    ww.value = int(float(v))\n",
    "                elif typ == \"float\":\n",
    "                    ww.value = float(v)\n",
    "                elif typ == \"bool\":\n",
    "                    ww.value = _parse_bool(v)\n",
    "                else:\n",
    "                    # normalize categorical to valid options\n",
    "                    vv = v.strip()\n",
    "                    if wname == \"w_cmode\":\n",
    "                        vv = vv.lower()\n",
    "                        if vv not in (\"local\",\"hybrid\",\"ring\",\"anchor\",\"anchor_strict\"):\n",
    "                            continue\n",
    "                    if wname == \"w_ch\":\n",
    "                        vv = vv.upper() if vv.lower()==\"iqr\" else vv\n",
    "                        if vv not in (\"p99\",\"IQR\",\"ACE\",\"Off\"):\n",
    "                            continue\n",
    "                    if wname == \"w_viz\":\n",
    "                        vv = vv.capitalize()\n",
    "                        if vv not in (\"Auto\",\"Fixed\"):\n",
    "                            continue\n",
    "                    ww.value = vv\n",
    "                changes.append(f\"{k}\u00e2\u2020\u2019{ww.value}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        with out_info:\n",
    "            if changes:\n",
    "                print(\"\u00e2\u0153\u201d Settings angewendet:\", \", \".join(changes))\n",
    "            else:\n",
    "                print(\"\u00e2\u201e\u00b9 Keine g\u00c3\u00bcltigen Schl\u00c3\u00bcssel gefunden (siehe Spickzettel).\")\n",
    "\n",
    "    def _run_once():\n",
    "        _ensure_loaded()\n",
    "        x,y,s = int(w_x.value), int(w_y.value), int(w_s.value)\n",
    "        return Epoxy_CyNif_af_roi(\n",
    "            STACK, int(w_tgt.value), (x,y,s,s),\n",
    "            ch_mode=w_ch.value, donor_sigma=float(w_sig.value),\n",
    "            kmad=float(w_kmad.value), mask_erode_px=int(w_er.value),\n",
    "            mask_close_px=int(w_cloM.value), mask_expand_px=int(w_dil.value),\n",
    "            huber_delta=float(w_hub.value), ridge_lambda=float(w_lam.value),\n",
    "            cap_kappa=float(w_ck.value), cap_win=int(w_cw.value),\n",
    "            closing_r=int(w_clos.value), median_k=int(w_med.value),\n",
    "            viz=w_viz.value,\n",
    "            pred_gain=float(w_gain.value), cap_mode=w_cmode.value,\n",
    "            ring_band_px=int(w_ring.value), donor_pow=float(w_pow.value),\n",
    "            anchor_bias_sd=float(w_bias.value), feather_px=int(w_fth.value),\n",
    "            genfill_on=bool(w_gf_on.value), gen_beta=float(w_gf_beta.value),\n",
    "            gen_octaves=int(w_gf_oct.value), gen_base_sigma=float(w_gf_sig.value),\n",
    "            gen_seed=int(w_gf_seed.value)\n",
    "        )\n",
    "\n",
    "    def on_run(ev=None):\n",
    "        out_panel.clear_output(True); out_info.clear_output(True)\n",
    "        try:\n",
    "            res = _run_once()\n",
    "            fig, axs = plt.subplots(2, 3, figsize=(22, 14))\n",
    "            axs[0,0].imshow(res[\"panel\"][\"raw\"],   cmap='gray'); axs[0,0].set_title(\"Zoom RAW\");   axs[0,0].axis('off')\n",
    "            axs[0,1].imshow(res[\"panel\"][\"dsum\"],  cmap='gray'); axs[0,1].set_title(\"Donor sum\"); axs[0,1].axis('off')\n",
    "            axs[0,2].imshow(res[\"panel\"][\"mask\"],  cmap='gray'); axs[0,2].set_title(\"Donor mask\");axs[0,2].axis('off')\n",
    "            axs[1,0].imshow(res[\"panel\"][\"c2\"],    cmap='gray'); axs[1,0].set_title(\"C2\");        axs[1,0].axis('off')\n",
    "            axs[1,1].imshow(res[\"panel\"][\"c3\"],    cmap='gray'); axs[1,1].set_title(\"C3\");        axs[1,1].axis('off')\n",
    "            axs[1,2].imshow(res[\"panel\"][\"clean\"], cmap='gray'); axs[1,2].set_title(\"Zoom CLEAN\");axs[1,2].axis('off')\n",
    "            with out_panel: display(fig); plt.close(fig)\n",
    "            m = res[\"meta\"]\n",
    "            with out_info:\n",
    "                print(\"\u00e2\u0153\u201d Preview ok.\")\n",
    "                print(f\"  Maskenanteil: {m['mask_pct']:.2f}% | w_c2={m['weights']['w_c2']:.4f} | w_c3={m['weights']['w_c3']:.4f}\")\n",
    "                print(f\"  Mask ops: shrink={m['mask_erode_px']} | close={m['mask_close_px']} | grow={m['mask_expand_px']}\")\n",
    "                if m['cap_mode'] in ('anchor','anchor_strict'):\n",
    "                    print(f\"  Anchor: bias\u00c3\u2014\u00cf\u0192={m['anchor_bias_sd']:.2f} | feather={m['feather_px']} px\")\n",
    "                if m.get('genfill_on', False):\n",
    "                    print(f\"  GenFill(exp): \u00ce\u00b2={m['gen_beta']:.2f}, octaves={m['gen_octaves']}, base \u00cf\u0192={m['gen_base_sigma']:.2f}, seed={m['gen_seed']}\")\n",
    "        except Exception as e:\n",
    "            with out_info: print(\"\u00e2\u0153\u2013 Fehler in Preview:\", e); traceback.print_exc()\n",
    "\n",
    "    def on_zip(ev=None):\n",
    "        try:\n",
    "            res = _run_once()\n",
    "            x,y,s = int(w_x.value), int(w_y.value), int(w_s.value)\n",
    "            zpath = save_preview_zip(res[\"panel\"], res[\"meta\"], IMG_PATH, (x,y,s), tag=\"Epoxy_CyNif_AF\")\n",
    "            with out_info:\n",
    "                print(\"\u00e2\u0153\u201d Preview-ZIP gespeichert:\")\n",
    "                print(\"  Ordner:\", os.path.dirname(zpath))\n",
    "                print(\"  Datei :\", os.path.basename(zpath))\n",
    "        except Exception as e:\n",
    "            with out_info: print(\"\u00e2\u0153\u2013 Fehler beim Speichern:\", e); traceback.print_exc()\n",
    "\n",
    "    w_load.on_click(lambda ev: _ensure_loaded())\n",
    "    w_over.on_click(on_over)\n",
    "    btn_apply.on_click(on_apply)\n",
    "    btn_run.on_click(on_run)\n",
    "    btn_zip.on_click(on_zip)\n",
    "\n",
    "    for _ctrl in (w_ace_alpha, w_ace_radius, w_ace_gain, w_ace_post):\n",
    "        _ctrl.observe(_update_ace_params, names=\"value\")\n",
    "    _update_ace_params()\n",
    "\n",
    "    # Layout\n",
    "    info_workflow = widgets.HTML(\"\"\"\n",
    "    <div style=\\\"padding:6px 0;\\\">\n",
    "      <b>Workflow:</b>\n",
    "      <ol style=\\\"margin:4px 0 0 20px;\\\">\n",
    "        <li>Histogramm-Normalisierung per <code>run_uniform_histogram_normalization_dynamic(...)</code> auf dem Roh-Stack ausf\u00c3\u00bchren.</li>\n",
    "        <li>Den erzeugten <code>*_Histo_Norm.ome.tif</code>-Pfad in das Feld <b>OME-TIF</b> unten einf\u00c3\u00bcgen (oder stehen lassen, falls bereits automatisch gesetzt).</li>\n",
    "        <li>AF-Removal und optional ACE-Optimierung \u00c3\u00bcber die Regler starten.</li>\n",
    "      </ol>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    row_path = widgets.HBox([w_path, w_load, w_over])\n",
    "    row_roi  = widgets.HBox([w_tgt, w_x, w_y, w_s, w_ch, w_viz, w_ace_post])\n",
    "\n",
    "    row_ace  = widgets.HBox([w_ace_alpha, w_ace_radius, w_ace_gain])\n",
    "    row_parA = widgets.HBox([w_sig, w_kmad, w_er, w_cloM, w_dil])\n",
    "    row_parB = widgets.HBox([w_hub, w_lam, w_ck, w_cw, w_clos, w_med])\n",
    "    row_patch= widgets.HBox([w_gain, w_cmode, w_ring, w_pow, w_bias, w_fth])\n",
    "    row_gf   = widgets.HBox([w_gf_on, w_gf_beta, w_gf_oct, w_gf_sig, w_gf_seed])\n",
    "    row_txt  = widgets.HBox([w_txt, btn_apply])\n",
    "    row_act  = widgets.HBox([btn_run, btn_zip])\n",
    "\n",
    "    out_over_placeholder = widgets.HTML(\"<hr><b>Overview (klickbar)</b>\")\n",
    "    out_panel_placeholder= widgets.HTML(\"<hr><b>Preview</b>\")\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        info_workflow,\n",
    "        row_path, row_roi,\n",
    "        widgets.HTML(\"<b>ACE Normalisierung</b>\"),\n",
    "        row_ace,\n",
    "        widgets.HTML(\"<hr><b>Settings-Zeile</b> (Key=Value, Leerzeichen-getrennt)\"),\n",
    "        row_txt,\n",
    "        widgets.HTML(\"<hr><b>Epoxy_CyNif-AF Parameter</b>\"),\n",
    "        row_parA, row_parB,\n",
    "        widgets.HTML(\"<b>Patches + Background-Anchor</b>\"),\n",
    "        row_patch,\n",
    "        widgets.HTML(\"<b>GenFill (exp) \u00e2\u20ac\u201d optional</b>\"),\n",
    "        row_gf,\n",
    "        row_act,\n",
    "        out_panel_placeholder, out_panel,\n",
    "        out_over_placeholder,  out_over,\n",
    "        widgets.HTML(\"<hr><b>Info</b>\"),\n",
    "        out_info\n",
    "    ])\n",
    "    display(ui)\n",
    "\n",
    "# -------- Start UI --------\n",
    "# _build_ui()  # UI deaktiviert f\u00c3\u00bcr Batch-Lauf\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Marker-Referenz & AF-Prozess ----------\n",
    "OME_NS = {'ome': 'http://www.openmicroscopy.org/Schemas/OME/2016-06'}\n",
    "\n",
    "# MARKER_TABLE_PATH wird sp\u00c3\u00a4ter dynamisch aus BASE_EXPORT geladen (siehe weiter unten)\n",
    "\n",
    "def load_marker_reference(csv_path: Path):\n",
    "    include_rows = []\n",
    "    with open(csv_path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if row.get('Include', '').strip().upper() == 'TRUE':\n",
    "                include_rows.append(row)\n",
    "    \n",
    "    # Berechne theoretischen globalen Channel-Index: (cycle - 1) * 10 + channel_index\n",
    "    # WICHTIG: Dieser Index ist NUR f\u00c3\u00bcr Sortierung und cycle_to_donors!\n",
    "    # Die tats\u00c3\u00a4chliche Stack-Position ist der Index nach Sortierung (0...95)\n",
    "    def get_global_channel_idx(row):\n",
    "        cycle = int(row['cycle'])\n",
    "        \n",
    "        # Robuste Spalten-Erkennung: 'channel index' oder 'No' oder 'index'\n",
    "        if 'channel index' in row:\n",
    "            ch_idx = int(row['channel index'])\n",
    "        elif 'No' in row:\n",
    "            ch_idx = int(row['No'])\n",
    "        elif 'index' in row:\n",
    "            ch_idx = int(row['index'])\n",
    "        else:\n",
    "            raise KeyError(f\"Keine 'channel index'/'No'/'index' Spalte gefunden in: {list(row.keys())}\")\n",
    "        \n",
    "        return (cycle - 1) * 10 + ch_idx\n",
    "    \n",
    "    # Sortiere nach globalem theoretischen Index\n",
    "    include_rows.sort(key=get_global_channel_idx)\n",
    "    \n",
    "    # KRITISCH: stack_pos_to_cycle_ch speichert f\u00c3\u00bcr jede Stack-Position (0...95) \n",
    "    # die urspr\u00c3\u00bcnglichen cycle/channel-Werte\n",
    "    stack_pos_to_cycle_ch = {}\n",
    "    for stack_pos, row in enumerate(include_rows):\n",
    "        cycle = int(row['cycle'])\n",
    "        if 'channel index' in row:\n",
    "            ch_idx = int(row['channel index'])\n",
    "        elif 'No' in row:\n",
    "            ch_idx = int(row['No'])\n",
    "        elif 'index' in row:\n",
    "            ch_idx = int(row['index'])\n",
    "        else:\n",
    "            ch_idx = 0\n",
    "        stack_pos_to_cycle_ch[stack_pos] = (cycle, ch_idx)\n",
    "    \n",
    "    # Identifiziere AF1/AF2 Donor Stack-Positionen pro Cycle\n",
    "    cycle_to_donors = {}\n",
    "    for stack_pos, row in enumerate(include_rows):\n",
    "        cycle = int(row['cycle'])\n",
    "        marker = (row.get('Marker-Name') or '').strip().lower()\n",
    "        \n",
    "        if marker == 'af1':\n",
    "            cycle_to_donors.setdefault(cycle, [None, None])[0] = stack_pos\n",
    "        elif marker == 'af2':\n",
    "            cycle_to_donors.setdefault(cycle, [None, None])[1] = stack_pos\n",
    "    \n",
    "    cycle_to_donors = {\n",
    "        cycle: tuple(n for n in pair if n is not None)\n",
    "        for cycle, pair in cycle_to_donors.items()\n",
    "    }\n",
    "    \n",
    "    return include_rows, stack_pos_to_cycle_ch, cycle_to_donors\n",
    "\n",
    "\n",
    "def is_base_marker(name: str) -> bool:\n",
    "    if not name:\n",
    "        return False\n",
    "    n = name.strip().lower()\n",
    "    if n in ('dapi', 'af1', 'af2'):\n",
    "        return True\n",
    "    if n.startswith('af') or 'autofluor' in n:\n",
    "        return True\n",
    "    if 'blank' in n:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def prepare_donor(array: np.ndarray, sigma: float, donor_pow: float) -> np.ndarray:\n",
    "    out = array.astype(np.float32, copy=True)\n",
    "    if sigma > 0:\n",
    "        out = ndi.gaussian_filter(out, sigma)\n",
    "    if abs(donor_pow - 1.0) > 1e-3:\n",
    "        out = np.power(np.maximum(0.0, out), donor_pow)\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_mask_from_sum(dsum: np.ndarray, params: dict) -> np.ndarray:\n",
    "    med = np.median(dsum)\n",
    "    mad = _mad(dsum)\n",
    "    thr = med + params['kmad'] * mad\n",
    "    mask = (dsum > thr)\n",
    "    if params.get('mask_erode_px', 0) > 0:\n",
    "        mask = morph.binary_erosion(mask, footprint=disk(int(params['mask_erode_px'])))\n",
    "    if params.get('mask_close_px', 0) > 0:\n",
    "        mask = morph.binary_closing(mask, footprint=disk(int(params['mask_close_px'])))\n",
    "    if params.get('mask_expand_px', 0) > 0:\n",
    "        mask = morph.binary_dilation(mask, footprint=disk(int(params['mask_expand_px'])))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def huber_ridge_multi(donor_arrays, target, mask, lam=1e-4, delta=2.5, iters=5):\n",
    "    if not donor_arrays:\n",
    "        return np.zeros(0, dtype=np.float32)\n",
    "    y = target[mask].astype(np.float32, copy=False)\n",
    "    if y.size == 0:\n",
    "        return np.zeros(len(donor_arrays), dtype=np.float32)\n",
    "    X = np.stack([arr[mask].astype(np.float32, copy=False) for arr in donor_arrays], axis=1)\n",
    "    lamI = lam * np.eye(X.shape[1], dtype=np.float32)\n",
    "    XtX = X.T @ X + lamI\n",
    "    Xty = X.T @ y\n",
    "    w = np.linalg.lstsq(XtX, Xty, rcond=None)[0]\n",
    "    for _ in range(max(1, iters)):\n",
    "        residual = y - X @ w\n",
    "        scale = _mad(residual) + 1e-6\n",
    "        thr = float(delta) * scale\n",
    "        weights = np.ones_like(residual, dtype=np.float32)\n",
    "        heavy = np.abs(residual) > thr\n",
    "        weights[heavy] = thr / np.maximum(np.abs(residual[heavy]), 1e-6)\n",
    "        sqrt_w = np.sqrt(weights)\n",
    "        Xw = X * sqrt_w[:, None]\n",
    "        yw = y * sqrt_w\n",
    "        XtX = Xw.T @ Xw + lamI\n",
    "        Xty = Xw.T @ yw\n",
    "        w = np.linalg.lstsq(XtX, Xty, rcond=None)[0]\n",
    "    return np.maximum(0.0, w)\n",
    "\n",
    "\n",
    "def parse_af_refs(raw: str) -> list[int]:\n",
    "    if not raw:\n",
    "        return []\n",
    "    raw = raw.strip()\n",
    "    if not raw or raw.lower().startswith('na'):\n",
    "        return []\n",
    "    tokens = raw.replace(',', ';').split(';')\n",
    "    refs = []\n",
    "    for token in tokens:\n",
    "        token = token.strip()\n",
    "        if token.isdigit():\n",
    "            refs.append(int(token))\n",
    "    return refs\n",
    "\n",
    "\n",
    "def refine_af_mask(mask, pred, tgt, params):\n",
    "    if mask is None or not np.any(mask):\n",
    "        return mask\n",
    "    mask = mask.astype(bool, copy=True)\n",
    "    pred_masked = pred[mask]\n",
    "    if pred_masked.size == 0:\n",
    "        return mask\n",
    "    med = np.median(pred_masked)\n",
    "    mad = _mad(pred_masked) + 1e-6\n",
    "    z = np.zeros_like(pred, dtype=np.float32)\n",
    "    z[mask] = (pred[mask] - med) / mad\n",
    "    sigma_thr = float(params.get('refine_sigma', 1.5))\n",
    "    core = mask & (z > sigma_thr)\n",
    "\n",
    "    ratio_min = float(params.get('refine_min_ratio', 0.4))\n",
    "    if ratio_min > 0:\n",
    "        ratio = np.zeros_like(pred, dtype=np.float32)\n",
    "        ratio[mask] = pred[mask] / (tgt[mask] + 1e-6)\n",
    "        core &= ratio >= ratio_min\n",
    "\n",
    "    guard_ratio = float(params.get('refine_guard_ratio', 6.0))\n",
    "    if guard_ratio > 0:\n",
    "        guard = np.zeros_like(pred, dtype=np.float32)\n",
    "        guard[mask] = (tgt[mask] + 1e-6) / (pred[mask] + 1e-6)\n",
    "        core &= guard <= guard_ratio\n",
    "\n",
    "    min_size = int(params.get('refine_min_size', 6))\n",
    "    if min_size > 1:\n",
    "        core = morph.remove_small_objects(core, min_size=min_size)\n",
    "    max_size = int(params.get('refine_max_size', 0))\n",
    "    if max_size > 0:\n",
    "        lbl, n = ndi.label(core)\n",
    "        if n > 0:\n",
    "            counts = np.bincount(lbl.ravel())\n",
    "            for idx in range(1, len(counts)):\n",
    "                if counts[idx] > max_size:\n",
    "                    core[lbl == idx] = False\n",
    "\n",
    "    dil = int(params.get('refine_dilate', 1))\n",
    "    ero = int(params.get('refine_erode', 0))\n",
    "    if dil > 0:\n",
    "        core = morph.binary_dilation(core, footprint=disk(dil))\n",
    "    if ero > 0:\n",
    "        core = morph.binary_erosion(core, footprint=disk(ero))\n",
    "    return core\n",
    "\n",
    "\n",
    "def build_global_seed(stack, donor_indices, params):\n",
    "    if not donor_indices:\n",
    "        return None\n",
    "    accum = np.zeros(stack.shape[1:], dtype=np.float32)\n",
    "    for idx in donor_indices:\n",
    "        arr = prepare_donor(stack[idx], params['donor_sigma'], params['donor_pow'])\n",
    "        accum = np.maximum(accum, arr)\n",
    "    mask = build_mask_from_sum(accum, params)\n",
    "    if not np.any(mask):\n",
    "        return mask\n",
    "    seed = morph.remove_small_objects(mask, min_size=int(max(4, params.get('refine_min_size', 6))))\n",
    "    dil = int(params.get('refine_dilate', 1))\n",
    "    if dil > 0:\n",
    "        seed = morph.binary_dilation(seed, footprint=disk(dil))\n",
    "    return seed\n",
    "\n",
    "\n",
    "# ---------- Globaler AF-Lauf ----------\n",
    "PARAMS = {\n",
    "    'kmad': 5.5,\n",
    "    'pred_gain': 1.35,  # ERH\u00c3\u2013HT von 1.12: St\u00c3\u00a4rkere AF-Korrektur\n",
    "    'donor_sigma': 1.6,\n",
    "    'donor_pow': 1.10,\n",
    "    'mask_erode_px': 0,\n",
    "    'mask_close_px': 3,\n",
    "    'mask_expand_px': 1,\n",
    "    'huber_delta': 3.0,  # ERH\u00c3\u2013HT von 2.5: Weniger aggressive Outlier-Behandlung\n",
    "    'ridge_lambda': 1e-6,  # REDUZIERT von 1e-4: Weniger D\u00c3\u00a4mpfung der Gewichte\n",
    "    'cap_mode': 'local',  # GE\u00c3\u201eNDERT von 'anchor_strict': Weniger restriktiv, nutzt raw_sub direkt\n",
    "    'cap_kappa': 2.5,  # ERH\u00c3\u2013HT von 1.8: H\u00c3\u00b6heres Cap f\u00c3\u00bcr st\u00c3\u00a4rkere Signale\n",
    "    'cap_win': 15,\n",
    "    'ring_band_px': 5,\n",
    "    'anchor_bias_sd': 0.15,  # ERH\u00c3\u2013HT von 0.05: H\u00c3\u00b6herer Anchor-Wert falls anchor_strict wieder aktiviert\n",
    "    'feather_px': 3,  # ERH\u00c3\u2013HT von 0: Weichere \u00c3\u0153berg\u00c3\u00a4nge am Rand \u00e2\u2020\u2019 reduziert \"breiten Rand\"\n",
    "    'genfill_on': False,\n",
    "    'fill_sigma': 6.0,\n",
    "    'blend_softness': 1.0,\n",
    "    'gen_beta': 0.5,\n",
    "    'gen_octaves': 4,\n",
    "    'gen_base_sigma': 1.2,\n",
    "    'gen_seed': 123,\n",
    "    'closing_r': 0,\n",
    "    'median_k': 1,\n",
    "    'refine_sigma': 1.5,\n",
    "    'refine_min_ratio': 0.4,\n",
    "    'refine_guard_ratio': 6.0,\n",
    "    'refine_min_size': 6,\n",
    "    'refine_max_size': 0,\n",
    "    'refine_dilate': 1,\n",
    "    'refine_erode': 0,\n",
    "}\n",
    "\n",
    "# MARKER_TABLE_PATH dynamisch aus BASE_EXPORT laden\n",
    "sample_token = ''.join(ch for ch in SAMPLE_ID if ch.isdigit()) or SAMPLE_ID\n",
    "marker_candidates = list(BASE_EXPORT.glob(f'markers_{sample_token}.csv'))\n",
    "if not marker_candidates:\n",
    "    marker_candidates = list(BASE_EXPORT.glob('markers_*.csv'))\n",
    "if not marker_candidates:\n",
    "    raise FileNotFoundError(\n",
    "        f\"\u00e2\u009d\u0152 FEHLER: Keine Marker-CSV gefunden in: {BASE_EXPORT}\\n\"\n",
    "        f\"  Erwartet: markers_{sample_token}.csv\"\n",
    "    )\n",
    "MARKER_TABLE_PATH = marker_candidates[0]\n",
    "print(f\"[CONFIG] Marker-CSV: {MARKER_TABLE_PATH}\")\n",
    "\n",
    "print(\"\u00f0\u0178\u201d\u00a7 Starte AF-Entfernung f\u00c3\u00bcr den kompletten Stack ...\")\n",
    "marker_rows, no_to_idx, cycle_to_donors = load_marker_reference(MARKER_TABLE_PATH)\n",
    "print(f\"  Marker-Referenzen: {len(marker_rows)} Kan\u00c3\u00a4le (Include=TRUE)\")\n",
    "\n",
    "with tiff.TiffFile(IMG_PATH) as tf:\n",
    "    series = tf.series[0]\n",
    "    axes = series.axes\n",
    "    orig_dtype = series.dtype\n",
    "    stack_raw = series.asarray()\n",
    "    channel_info, px_sizes = parse_ome_channels(tf.ome_metadata)\n",
    "    px_meta = sanitize_pixel_sizes(px_sizes)\n",
    "\n",
    "axes_list = list(axes)\n",
    "extra_dims = []\n",
    "for dim, ax in enumerate(axes_list):\n",
    "    if ax not in ('C', 'Y', 'X'):\n",
    "        extra_dims.append(dim)\n",
    "\n",
    "if extra_dims:\n",
    "    for dim in sorted(extra_dims, reverse=True):\n",
    "        if stack_raw.shape[dim] != 1:\n",
    "            raise RuntimeError(f\"Achse '{axes_list[dim]}' hat Gr\u00c3\u00b6\u00c3\u0178e {stack_raw.shape[dim]} (\u00e2\u2030\u00a01) \u00e2\u20ac\u201c kann nicht automatisch reduziert werden.\")\n",
    "        stack_raw = np.take(stack_raw, indices=0, axis=dim)\n",
    "        axes_list.pop(dim)\n",
    "axes_reduced = ''.join(axes_list)\n",
    "perm = [axes_reduced.index('C'), axes_reduced.index('Y'), axes_reduced.index('X')]\n",
    "stack_raw = np.transpose(stack_raw, perm)\n",
    "axes = 'CYX'\n",
    "\n",
    "# SPEICHER-OPTIMIERUNG: Behalte stack_raw als uint16 (13 GB statt 26 GB)\n",
    "# Konvertiere nur einzelne Channels tempor\u00c3\u00a4r zu float32 bei Bedarf\n",
    "stack = stack_raw  # Kein .astype(np.float32) mehr!\n",
    "orig_dtype_for_processing = stack.dtype  # uint16\n",
    "C, H, W = stack.shape\n",
    "print(f\"  Eingelesen: {C} Kan\u00c3\u00a4le | Gr\u00c3\u00b6\u00c3\u0178e: {W}\u00c3\u2014{H} | dtype: {orig_dtype} | Achsen: {axes_reduced if extra_dims else axes}\")\n",
    "print(f\"  \u00e2\u0161\u00a0\u00ef\u00b8\u008f SPEICHER-MODUS: Behalte uint16 ({stack.nbytes / (1024**3):.1f} GB) statt float32-Konvertierung ({stack.nbytes * 2 / (1024**3):.1f} GB)\")\n",
    "\n",
    "if len(marker_rows) != C:\n",
    "    raise RuntimeError(f\"Marker-Referenz liefert {len(marker_rows)} Kan\u00c3\u00a4le, TIFF enth\u00c3\u00a4lt {C}.\")\n",
    "\n",
    "channel_names = []\n",
    "channel_meta_output = []\n",
    "channel_donor_idx = []\n",
    "skip_idx = set()\n",
    "for idx, row in enumerate(marker_rows):\n",
    "    name = (row.get('Marker-Name') or '').strip()\n",
    "    fluor = (row.get('fluorochrome') or '').strip()\n",
    "    if not name or name.upper() == 'NA':\n",
    "        name = fluor or f'Channel_{idx:02d}'\n",
    "    channel_names.append(name)\n",
    "    meta_entry = {'Name': name}\n",
    "    if fluor and fluor.upper() != 'NA':\n",
    "        meta_entry['Fluor'] = fluor\n",
    "    meta_entry['Cycle'] = row.get('cycle', '')\n",
    "    channel_meta_output.append(meta_entry)\n",
    "\n",
    "    cycle = int(row['cycle'])\n",
    "    \n",
    "    # AF_Ref wird nicht verwendet - wir verwenden cycle_to_donors\n",
    "    # cycle_to_donors enth\u00c3\u00a4lt bereits die korrekten Stack-Positionen f\u00c3\u00bcr AF1/AF2\n",
    "    donor_stack_positions = list(cycle_to_donors.get(cycle, []))\n",
    "    \n",
    "    # Entferne den aktuellen Channel selbst aus den Donors (falls vorhanden)\n",
    "    donor_stack_positions = [d for d in donor_stack_positions if d != idx]\n",
    "    \n",
    "    if is_base_marker(name):\n",
    "        skip_idx.add(idx)\n",
    "    \n",
    "    channel_donor_idx.append(donor_stack_positions)\n",
    "\n",
    "unique_donors = sorted({d for pair in channel_donor_idx for d in pair[:2]})\n",
    "global_seed = build_global_seed(stack, unique_donors, PARAMS) if unique_donors else None\n",
    "if global_seed is not None and np.any(global_seed):\n",
    "    print(f\"  Globale AF-Seed: {global_seed.mean()*100:.2f}% der Pixel\")\n",
    "else:\n",
    "    global_seed = None\n",
    "    print('  Hinweis: Keine globale AF-Saat gebildet (keine Donors oder leer).')\n",
    "\n",
    "# SPEICHER-OPTIMIERUNG: Erstelle processed erst sp\u00c3\u00a4ter channel-by-channel\n",
    "# Statt stack.copy() (13 GB Duplikat) \u00e2\u2020\u2019 preallocate nur bei Bedarf\n",
    "processed = np.empty_like(stack)  # Alloziert, aber noch nicht beschrieben\n",
    "donor_cache = {}\n",
    "mask_cache = {}\n",
    "log_lines = []\n",
    "for idx in range(C):\n",
    "    name = channel_names[idx]\n",
    "    donors_idx = channel_donor_idx[idx]\n",
    "\n",
    "    if idx in skip_idx or not donors_idx:\n",
    "        processed[idx] = stack[idx]\n",
    "        reason = 'Basis/AF-Kanal' if idx in skip_idx else 'keine Referenz'\n",
    "        msg = f\"[{idx+1}/{C}] \u00e2\u2020\u00b7 Kanal {idx:02d} ({name}): {reason}\"\n",
    "        print(msg, flush=True)\n",
    "        log_lines.append(msg)\n",
    "        continue\n",
    "\n",
    "    if len(donors_idx) < 2:\n",
    "        processed[idx] = stack[idx]\n",
    "        msg = f\"[{idx+1}/{C}] \u00e2\u2020\u00b7 Kanal {idx:02d} ({name}): weniger als zwei Donors\"\n",
    "        print(msg, flush=True)\n",
    "        log_lines.append(msg)\n",
    "        continue\n",
    "\n",
    "    donors_key = tuple(sorted(donors_idx[:2]))\n",
    "    d1_idx, d2_idx = donors_key\n",
    "\n",
    "    c2 = donor_cache.get(d1_idx)\n",
    "    if c2 is None:\n",
    "        c2 = prepare_donor(stack[d1_idx], PARAMS['donor_sigma'], PARAMS['donor_pow'])\n",
    "        donor_cache[d1_idx] = c2\n",
    "    c3 = donor_cache.get(d2_idx)\n",
    "    if c3 is None:\n",
    "        c3 = prepare_donor(stack[d2_idx], PARAMS['donor_sigma'], PARAMS['donor_pow'])\n",
    "        donor_cache[d2_idx] = c3\n",
    "\n",
    "    if donors_key in mask_cache:\n",
    "        mask = mask_cache[donors_key]\n",
    "    else:\n",
    "        dsum = c2 + c3\n",
    "        mask = build_mask_from_sum(dsum, PARAMS)\n",
    "        mask_cache[donors_key] = mask\n",
    "\n",
    "    if not np.any(mask):\n",
    "        processed[idx] = stack[idx]\n",
    "        msg = f\"[{idx+1}/{C}] \u00e2\u2020\u00b7 Kanal {idx:02d} ({name}): keine AF-Maske\"\n",
    "        print(msg, flush=True)\n",
    "        log_lines.append(msg)\n",
    "        continue\n",
    "\n",
    "    tgt = stack[idx]\n",
    "    wts = huber_ridge_2d(c2[mask], c3[mask], tgt[mask], lam=PARAMS['ridge_lambda'], delta=PARAMS['huber_delta'], iters=5)\n",
    "    pred = wts[0]*c2 + wts[1]*c3\n",
    "    raw_sub = tgt - PARAMS['pred_gain'] * pred\n",
    "\n",
    "    mask_refined = refine_af_mask(mask, pred, tgt, PARAMS)\n",
    "    if global_seed is not None:\n",
    "        mask_refined = mask_refined & global_seed\n",
    "    if not np.any(mask_refined):\n",
    "        processed[idx] = stack[idx]\n",
    "        msg = f\"[{idx+1}/{C}] \u00e2\u2020\u00b7 Kanal {idx:02d} ({name}): Maske entleert nach Refinement\"\n",
    "        print(msg, flush=True)\n",
    "        log_lines.append(msg)\n",
    "        continue\n",
    "\n",
    "    mask = mask_refined\n",
    "    wts = huber_ridge_2d(c2[mask], c3[mask], tgt[mask], lam=PARAMS['ridge_lambda'], delta=PARAMS['huber_delta'], iters=5)\n",
    "    pred = wts[0]*c2 + wts[1]*c3\n",
    "    raw_sub = tgt - PARAMS['pred_gain'] * pred\n",
    "\n",
    "    mu_loc, sd_loc = masked_local_mean_std(tgt, mask, win=int(PARAMS['cap_win']))\n",
    "    mu_ring, sd_ring = ring_mean_std(mask, tgt, band=int(PARAMS['ring_band_px']), win=int(PARAMS['cap_win']))\n",
    "    cap_local = mu_loc + PARAMS['cap_kappa']*sd_loc\n",
    "    cap_ring = mu_ring + PARAMS['cap_kappa']*sd_ring\n",
    "\n",
    "    cm = str(PARAMS['cap_mode']).lower()\n",
    "    \n",
    "    # DEBUG: Zeige Parameter f\u00c3\u00bcr diesen Channel\n",
    "    if idx == 0:\n",
    "        print(f\"\\n\u00f0\u0178\u201d\u008d DEBUG AF-REMOVAL PARAMETERS (Channel {idx}):\")\n",
    "        print(f\"   cap_mode: {PARAMS['cap_mode']}\")\n",
    "        print(f\"   feather_px: {PARAMS['feather_px']}\")\n",
    "        print(f\"   genfill_on: {PARAMS['genfill_on']}\")\n",
    "        print(f\"   mask_expand_px: {PARAMS['mask_expand_px']}\")\n",
    "        print(f\"   anchor_bias_sd: {PARAMS['anchor_bias_sd']}\\n\")\n",
    "    \n",
    "    if cm in ('anchor', 'anchor_strict'):\n",
    "        bias = float(PARAMS['anchor_bias_sd']) if PARAMS['anchor_bias_sd'] is not None else 0.0\n",
    "        anchor = np.maximum(0.0, mu_loc - bias * sd_loc)\n",
    "        anchor = np.minimum(anchor, tgt)\n",
    "        \n",
    "        if PARAMS['genfill_on']:\n",
    "            clean = genfill_exp_fill(\n",
    "                tgt, mask, mu_loc, sd_loc,\n",
    "                anchor_bias_sd=float(PARAMS['anchor_bias_sd']),\n",
    "                feather_px=int(PARAMS['feather_px']),\n",
    "                beta=float(PARAMS['gen_beta']),\n",
    "                octaves=int(PARAMS['gen_octaves']),\n",
    "                base_sigma=float(PARAMS['gen_base_sigma']),\n",
    "                seed=int(PARAMS['gen_seed'])\n",
    "            )\n",
    "        else:\n",
    "            base = np.maximum(raw_sub, 0.0)\n",
    "            clean = tgt.copy()\n",
    "            if int(PARAMS['feather_px']) > 0:\n",
    "                di = ndi.distance_transform_edt(mask)\n",
    "                w_blend = np.clip(di / float(PARAMS['feather_px']), 0.0, 1.0)\n",
    "                mix = (1.0 - w_blend)*base + w_blend*anchor\n",
    "                clean[mask] = np.minimum(mix[mask], tgt[mask])\n",
    "            else:\n",
    "                clean[mask] = np.minimum(anchor[mask], tgt[mask])\n",
    "    else:\n",
    "        # NON-ANCHOR MODI: Nutze raw_sub direkt, mit Cap als Sicherheit\n",
    "        base = np.maximum(raw_sub, 0.0)  # AF-korrigiertes Signal, clipped bei 0\n",
    "        \n",
    "        if cm == 'ring':\n",
    "            cap = cap_ring\n",
    "        elif cm == 'hybrid':\n",
    "            cap = np.minimum(cap_local, cap_ring)\n",
    "        elif cm == 'local':\n",
    "            cap = cap_local\n",
    "        else:\n",
    "            cap = np.minimum(cap_local, tgt)\n",
    "\n",
    "        cap = np.clip(cap, 0, tgt)\n",
    "        \n",
    "        # Verwende raw_sub direkt, aber mit Cap als obere Grenze f\u00c3\u00bcr Safety\n",
    "        clean = tgt.copy()\n",
    "        clean[mask] = np.minimum(base[mask], cap[mask])  # GE\u00c3\u201eNDERT: Nutze base (raw_sub) statt fill_candidate\n",
    "\n",
    "    if PARAMS['closing_r'] > 0:\n",
    "        clean = ndi.grey_closing(clean, size=(int(PARAMS['closing_r']), int(PARAMS['closing_r'])))\n",
    "    if PARAMS['median_k'] > 1:\n",
    "        clean = ndi.median_filter(clean, size=int(PARAMS['median_k']))\n",
    "\n",
    "    processed[idx] = clean\n",
    "    donors_label = ', '.join(f\"{d:02d}:{channel_names[d]}\" for d in donors_key)\n",
    "    weight_str = ', '.join(f\"w{j+1}={w:.4f}\" for j, w in enumerate(wts))\n",
    "    msg = f\"[{idx+1}/{C}] \u00e2\u0153\u2026 Kanal {idx:02d} ({name}): Referenz \u00e2\u2020\u2019 {donors_label} | {weight_str}\"\n",
    "    print(msg, flush=True)\n",
    "    log_lines.append(msg)\n",
    "params = ACE_PARAMS\n",
    "ace_post_widget = globals().get('w_ace_post')\n",
    "ace_enabled = params.get('post_enabled', True)\n",
    "if ace_post_widget is not None:\n",
    "    ace_enabled = bool(getattr(ace_post_widget, 'value', False))\n",
    "if ace_enabled:\n",
    "    print('[ACE] Post-Normalisierung aktiv -> radii=%s, alpha=%.2f, iter=%d, radius=%s' % (\n",
    "        params.get('radii'), params.get('alpha', 6.0), params.get('iterations', 1), params.get('radius')))\n",
    "    total_channels = processed.shape[0]\n",
    "    for _idx in range(total_channels):\n",
    "        print(f\"  [ACE] Kanal {_idx+1}/{total_channels} ...\", end=' ', flush=True)\n",
    "        processed[_idx] = ace_local_equalize(\n",
    "            processed[_idx],\n",
    "            radii=params.get('radii'),\n",
    "            alpha=params.get('alpha', 6.0),\n",
    "            iterations=params.get('iterations', 1),\n",
    "            clip=params.get('clip'),\n",
    "            radius=params.get('radius'),\n",
    "            preserve_background=params.get('preserve_background', True),\n",
    "            max_gain=params.get('max_gain', 3.0)\n",
    "        )\n",
    "        print('fertig', flush=True)\n",
    "else:\n",
    "    print('[ACE] Post-Normalisierung deaktiviert (post_enabled=False).')\n",
    "\n",
    "if np.issubdtype(orig_dtype, np.integer):\n",
    "    rng = np.iinfo(orig_dtype)\n",
    "    output_array = np.clip(processed, rng.min, rng.max).astype(orig_dtype)\n",
    "else:\n",
    "    output_array = processed.astype(orig_dtype)\n",
    "\n",
    "# OUTPUT IN AF_removal/-Ordner (dediziert, Pipeline-konform)\n",
    "af_removal_dir = BASE_EXPORT / \"AF_removal\"\n",
    "af_removal_dir.mkdir(exist_ok=True, parents=True)\n",
    "output_path = af_removal_dir / \"fused_decon_AF_cleaned.ome.tif\"\n",
    "\n",
    "metadata = {\n",
    "    'axes': 'CYX',\n",
    "    'DimensionOrder': 'XYCZT',\n",
    "    'Channel': channel_meta_output,\n",
    "    'SizeT': 1,\n",
    "    'SizeZ': 1,\n",
    "    'SignificantBits': int(np.iinfo(orig_dtype).bits if np.issubdtype(orig_dtype, np.integer) else 32)\n",
    "}\n",
    "metadata.update(px_meta)\n",
    "\n",
    "print('--- Kanal\u00c3\u00bcbersicht ---')\n",
    "success_count = sum('\u00e2\u0153\u2026' in line for line in log_lines)\n",
    "skip_count = sum('\u00e2\u2020\u00b7' in line for line in log_lines)\n",
    "print(f'  \u00e2\u0153\u2026 Gereinigt: {success_count}')\n",
    "print(f'  \u00e2\u2020\u00b7 \u00c3\u0153bersprungen: {skip_count}')\n",
    "\n",
    "print(f\"\u00f0\u0178\u2019\u00be Speichere vollst\u00c3\u00a4ndigen Stack nach {output_path}\")\n",
    "tiff.imwrite(\n",
    "    output_path,\n",
    "    output_array,\n",
    "    metadata=metadata,\n",
    "    ome=True,\n",
    "    photometric='minisblack',\n",
    "    bigtiff=True,\n",
    "    compression='zlib'\n",
    ")\n",
    "\n",
    "print(f\"  \u00c3\u0153bersprungene Kan\u00c3\u00a4le: {sorted(skip_idx)}\")\n",
    "print(\"  Fertig.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Epoxy_CyNif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}